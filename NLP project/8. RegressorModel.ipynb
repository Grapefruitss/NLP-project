{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2daeab-da7f-40b9-b60d-3b1d9e814a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e05ee5-9513-4328-be3a-9807cd365353",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\\\Users\\\\user\\\\Desktop\\\\hansol\\\\3rd_project\\\\NLP_new_\\\\NLP-project\\\\NLP project\\\\crawling_data\\\\(new)korean1-317.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file :\n",
    "    raw_cv = csv.reader(file)\n",
    "    c = list(raw_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717e77d2-d3c1-4ac3-b0c7-8e308257af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_letter = pd.DataFrame(data = c, columns=['text'])\n",
    "cover_letter['score']=3\n",
    "cover_letter.loc[:77, 'score'] = 4\n",
    "cover_letter.loc[:21, 'score'] = 5\n",
    "cover_letter.iloc[-142:, cover_letter.columns.get_loc('score')] = 2\n",
    "cover_letter.iloc[-15:, cover_letter.columns.get_loc('score')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dda6c0-4804-4727-ae40-4fa7730d62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    127\n",
      "3     97\n",
      "4     56\n",
      "5     22\n",
      "1     15\n",
      "Name: score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "score_counts = cover_letter['score'].value_counts()\n",
    "\n",
    "print(score_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d842cc44-673b-4973-bf43-11d0890ce241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score가 1, 2, 4, 5 행만 필터링\n",
    "filtered_cover_letter = cover_letter[cover_letter['score'].isin([1, 2, 4, 5])]\n",
    "\n",
    "# 텍스트와 라벨 분리\n",
    "texts = filtered_cover_letter['text'].astype(str).tolist()\n",
    "labels = filtered_cover_letter['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f082fd14-c1c9-48a3-b562-9cc4c21c3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea8683c-c33c-431e-9df8-99c91cf14bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.8445454545454543\n",
      "Root Mean Squared Error: 0.9189915421512074\n",
      "R² Score: 0.4101587301587303\n"
     ]
    }
   ],
   "source": [
    "#################################################### Doc2Vec 모델 학습\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# 학습 데이터를 태그된 문서로 변환\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(X_train)]\n",
    "\n",
    "# Doc2Vec 모델 설정 및 학습\n",
    "doc2vec_model = Doc2Vec(\n",
    "    vector_size=50,  # 벡터 차원 수\n",
    "    window=5,         # 컨텍스트 윈도우 크기\n",
    "    min_count=3,      # 최소 출현 빈도\n",
    "    epochs=20,        # 학습 반복 횟수\n",
    "    dm=1              # DM 모델 사용 (0이면 DBOW 모델 사용)\n",
    ")   \n",
    " \n",
    "\n",
    "# 모델 학습\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "####################################################### 벡터화 및 회귀 모델 학습\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 학습 데이터 벡터화\n",
    "X_train_vectors = [doc2vec_model.infer_vector(word_tokenize(doc.lower())) for doc in X_train]\n",
    "X_test_vectors = [doc2vec_model.infer_vector(word_tokenize(doc.lower())) for doc in X_test]\n",
    "\n",
    "# 회귀 모델 학습\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "regressor.fit(X_train_vectors, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = regressor.predict(X_test_vectors)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45d641e-8822-404e-9610-44f26fe7d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R² Score: 0.4672650793650793\n",
      "Best Parameters: {'dm': 1, 'epochs': 20, 'min_count': 2, 'vector_size': 50, 'window': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# 파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'vector_size': [50, 100, 150],\n",
    "    'window': [3, 5, 7],\n",
    "    'min_count': [1, 2, 3],\n",
    "    'epochs': [20, 40, 60],\n",
    "    'dm': [0, 1]\n",
    "}\n",
    "\n",
    "best_score = float('-inf')\n",
    "best_params = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = Doc2Vec(\n",
    "        vector_size=params['vector_size'],\n",
    "        window=params['window'],\n",
    "        min_count=params['min_count'],\n",
    "        workers=4,\n",
    "        epochs=params['epochs'],\n",
    "        dm=params['dm']\n",
    "    )\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    \n",
    "    # 벡터화\n",
    "    X_train_vectors = [model.infer_vector(word_tokenize(doc.lower())) for doc in X_train]\n",
    "    X_test_vectors = [model.infer_vector(word_tokenize(doc.lower())) for doc in X_test]\n",
    "    \n",
    "    # 회귀 모델 학습 및 평가\n",
    "    regressor = RandomForestRegressor(n_estimators=100, random_state=123)\n",
    "    regressor.fit(X_train_vectors, y_train)\n",
    "    y_pred = regressor.predict(X_test_vectors)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    if r2 > best_score:\n",
    "        best_score = r2\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best R² Score: {best_score}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c638aa-e1c7-492b-969f-b2efa9eb2dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.2484067049804162\n",
      "Root Mean Squared Error: 1.1173212183523662\n",
      "R² Score: 0.12809690445812216\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=123), param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
    "grid_search.fit(X_train_vectors, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_vectors)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aea06e-0e68-4507-8667-73ce1de830b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
