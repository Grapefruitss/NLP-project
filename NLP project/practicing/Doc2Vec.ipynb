{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceefb8c-cb56-4677-b8a4-cdc7fd25f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5818a74e-aadc-439d-90d1-5b4a05840bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['text', 'label'], ['My family consists of four members: my father, mother, older sister and me, who are office workers. During my school years, I was interested in reading books and continued to read books in a wide range of fields, especially reading classics such as the biography of great men, classics, and Eastern and Western philosophy. As a result, I have acquired the ability to understand and empathize with various human images, excellent reason and logic, while also building up my knowledge of the humanities and trying to imitate great men. Because of these traits, I made friendship with friends who like reading books and who have desirable moral senses and humility, and I studied based on my sincere lifestyle by going to school early in the morning and leaving school after self-study at night, following the example of sincere and honest parents. After reading Lee Ji-sung\\'s \"Dreaming Attic Room,\" I realized that by having a big dream, the criminal can be reborn as a great man and eventually achieve that dream, and this greatly influenced me, so that I have a lifelong dream to live a better society.\" \"There is a case in which I was greatly frustrated at the beginning due to my lack of skills in analyzing data allocated during the internship program at the AI research institute OOO, but I eventually achieved the best performance among internships by building strategic competencies and overcoming them. Having the most insufficient data analysis capabilities among interns, I was assigned certain predictive accuracy calculations by seven laggle competitions, but voluntarily challenged larger goals and implemented strategies to systematically grow my capabilities by overachieving work-level overachievement. As a result, I achieved the highest performance and received incentives and full-time offers.\", The securities industry majored in business administration hoping to become a financier as it guarantees a stable economic life for its customers with data-based strategies and insights. As I decided on my career path as an IT job, I have dreamed of creating a customer-friendly business digital platform that is integrated with customers\\' daily lives based on data analysis and AI in the securities industry. Through my management domain-based big data analysis and AI implementation capabilities and SW app development capabilities, Korea Investment & Securities has supported me to contribute to the improvement of our Korean investment, Ministock and Bankies FinTech services, online financial gift certificates, and AI Research AI Air services.\" We are applying to the Trading Development Department and the BIZ Development Department within the IT headquarters, which are responsible for the development of trading and mobile apps, and the development of securities business from the front to the back office. Through this, we will establish an internal system of sales and management departments in charge of securities business in the enterprise and provide SW services, and develop fintech apps to enhance the convenience of our customers\\' financial business.\"\", and \"As a management IT convergence talent, I am suitable for the IT job of Korea Investment & Securities because I can improve Korea Investment & Securities\\' fintech service and air AI service into a business SW solution optimized for meeting customer business needs based on my client and business understanding. After majoring in business administration and computer science, I analyzed actual management big data in the internship at OOO, an AI research institute, and came up with the optimal solution. We are preparing to present MFE and AutoML implementation papers at the KCI Society through the Meta feature extraction technology research research study for AutoML. In addition, we have carried out web full stack development in the OOO Capstone project and OOO SW contest, and among them, we won the Excellence Award in the OOO SW contest. I developed an Android app in the OOO-linked industry project and the App Dev and Capstone projects in OOO that were dispatched as software scholarship students, and received an A grade in OOO.\",\"\"I have a dream to improve the quality of life of my customers and create a more advanced and happy society by creating a business digital platform optimized for their needs through digital financial innovation that combines management and SW.\" Korea Investment & Securities is implementing an effective financial digital strategy and development of fintech platforms at the same time through its connection with big tech companies such as Kakao and innovative financial services. Joining Korea Investment & Securities\\' current challenges to bring joy to customers and create new value through DT will help me realize my dream as well as achieve corporate goals in the future. I will improve fintech services in a customer-friendly way in the IT job, and build an optimized enterprise-wide system, SW platform, and enterprise-wide data governance system that takes into account the business characteristics of each business unit of Korea Investment & Securities. This will help me realize my dream in that I can contribute to the development of the global society and the improvement of the quality of life by contributing to the global digital finance leadership of companies through continuous DT.\",,,,', '1'], ['In the summer of the fourth grade, an AI research institute challenged me for an AI engineering internship for two months. Three of the seven laggle competitions were assigned to calculate prediction accuracy within 40%, and four were assigned to calculate prediction accuracy within 100%, but I voluntarily challenged the goal of calculating prediction accuracy within 40% of all seven. I set a goal to derive a solution focusing on competition, which analyzes the DB of global companies using the management major domain. At first, I thought that the possibility of achieving the goal was close to zero because I had the most lack of data analysis experience and AI capabilities among interns. In fact, in the beginning, I was frustrated because I did not know how to use basic open sources such as PANDAs and Sykitruns. So to achieve the final goal, we classified the difficulty of competition from 1 to 7, selected seven competitions including all difficulties, and established a strategy to achieve systematic competency growth and final goal through step-by-step overachievement. As a result of persistent accumulation of competency, I achieved the best performance among interns, receiving incentives and offers for full-time employment. In addition, I am preparing to publish MFE and AutoML research results as papers. Based on this experience, even after joining SK C&C, if I challenge myself with new skills and learning without fear, I will build up the necessary competencies and eventually overcome them.\" \"I went to the SW contest in the school and showed my passion to achieve my goal of winning the award despite the limited time due to my lack of web development skills and job preparation. My existing development method was to implement it step by step by step by looking at the textbook. However, with the deadline approaching, the result was a basic level, so I boldly took a new approach. It was to study the optimal library and implementation method necessary for implementing the function by referring to the source code that already implemented the function I wanted. The reason I made a bold attempt was because I wanted to present the joy of winning the award to a team member who trusted and followed me, who was not good enough. However, my friends gave me a negative opinion that they would not understand the difficult codes because they were preparing for employment, and they did not have enough time to invest in development. In order to build up development capabilities, I focused only on web development with my team members for the rest of the days, while completing other studies early by minimizing unnecessary time spent in daily life and increasing the number of study hours a day to 10 hours a week. Seeing this, my friends also gave me a lot of advice. As a result, the team was able to win the award by implementing the initially targeted elementary school education support web app called \"OOO,\" which includes video chat, real-time conversation, and bulletin board functions. I will become an engineer who is also creative in SK C&C.\",,,,', '1'], ['I was impressed by watching/cleaning movies, respectful people, and practicing values. I don\\'t want to be a sparrow passing by the mill. I want to discover unknown insights from Cheil Worldwide\\'s digital panel data. While studying data analysis, I was interested in customer behavior data. I enjoyed the process of analyzing people\\'s behavior in multiple dimensions and finding meaning. I was naturally interested in the advertising industry, where customer data was collected in real-time and used for decision-making. While spending my first internship at an advertising company, you can feel the data-friendly atmosphere of the advertising industry directly on the spot. In particular, Cheil Worldwide is the most active in implementing the data-driven business among many advertising companies. We secure high-quality data by operating large-scale digital panels centered on the DNA center. I would like to proceed with the project so that meaningful planning can be achieved by analyzing this. I want to create a variable that is close to CDM by processing the existing variable that exists in the digital panel data. I have experience dealing with LPoint\\'s customer log data through a competition. Elaborate targeting of retention members was performed by using the \\'traces\\' variables that accumulated and averaged existing variables based on access behavior. Since Cheil\\'s panel data is collected from various channels, the amount of variables will be significant. I would like to apply various methodologies to find the criteria for customer segmentation by exploring all variables one by one. \"Since childhood, I have considered a clear sense of goal as a virtue. I enjoyed the process of making plans to achieve my goals, and implementing them step by step. It was the secret to having a pleasant time in my school days marked by competition and examination. However, things have changed since I went to college. I was not able to enter the department I wanted, so I was not motivated why I had to study statistics. The reason I recovered my sense of goal was mentoring. Over three years, I have met about 200 high school mentees while working in an educational volunteer club. Ironically, I have looked back on myself while consulting students who are struggling with their grades. Locking myself within the framework of grades and underestimating myself was their common problem. He advised me to \"break the mold and look at myself.\" In addition to grades, I also looked for factors that could positively evaluate me. It was a time to enlighten myself. It was an opportunity to reflect on myself, who was trapped within the framework of \\'not suitable for aptitude\\' and did not try to find meaning. The choice I made after enlightenment was a conflict. I entered the Big Data Society with the determination to study data analysis from the beginning. While working at the society for a year, I studied programming, basic statistics, and machine learning. Life in the society became an opportunity to set my goal to become a data analyst. I enjoyed the process of deriving answers that fit the purpose from the numbers of complex matrices. I was also able to learn attitudes toward data from colleagues in various majors such as sound engineering and sociology. Seeing colleagues trying to use data in their respective fields, I became greedy to find such a domain. When I opened my eyes, I abandoned my previous passive attitude. I grew together by sharing the experience beyond studying with the members of the society. After forming a group, I learned deep learning techniques that were not present in the original curriculum and transcribed excellent codes in the calligraphy. I formed a team to experience different kinds of data and participated in six contests. At the same time as being honored, I was able to discover my own taste in data that I wanted to study for the rest of my life. I started an internship at the same time as an academic conference. I wanted to experience the data use field. I worked at an advertising agency to collect basic data. By voluntarily automating work in a programming language, I was able to shorten the time required from 5 days to 3 days. Through the small experience of success, I was able to see the importance of an attitude to be active in work. I also worked for a platform company that runs big data contests because I wanted to deal with them myself and apply algorithms. Before the contest, I devised problems in the contest by analyzing and processing initial data from clients, and after the contest, I reviewed the codes for excellent works. I was able to improve my understanding of data and learn several methodologies. The two internship experiences remain as traces of my passionate and goal-consciousness.\",\" said the three data law amendments allow me to analyze customer behavior patterns precisely. The Data Act 3 refers to the three laws: the Personal Information Protection Act, the Information and Communication Network Act, and the Credit Information Act. The gist of the amendment is to consider ways to use personal information as data by revising this, but to give companies a sense of responsibility by presenting clear standards. The advantage of the amendment in my opinion is the potential of pseudonymous information. Pseudonym information is data that removes information that can identify individuals such as name, resident registration number, and phone number from personal information. For statistical analysis purposes, pseudonymous information data can be used without the consent of the customer regardless of the purpose. In addition, since the data of different companies can be combined through specialized institutions, different data can be combined and utilized with existing data. It is expected that financial and medical data, which have been difficult to access because it has been treated as sensitive information, will be actively utilized. I think that this sensitive information will also be used in the advertising market. Due to the digitization of customer behavior, the amount of data that individuals produce per day is significant. Various variables are needed to elaborately design personalized services. The customer segment can be subdivided based on sensitive information, thereby enabling more rational targeting. For example, in combination with financial and credit information data, a recommendation service can be devised that takes into account various financial conditions such as the customer\\'s loan status, balance, and credit score. In particular, Cheil expects to create greater synergy by fusion of other data with digital panel data.Data analysts need a higher level of communication skills. As the volume of data increases, I think the importance of collaboration will emerge. In particular, domain knowledge is often required to deal with sensitive information, so collaboration with experts is required. Therefore, communication skills are as important as data analysis capabilities. I think a proven analyst who has successfully performed collaboration processes such as projects and contests is the reason why first planning needs it.\",,,,', '1'], ['\"I want to contribute to innovation with statistical capabilities that I have developed using coding.\" The first major class that caught my attention as a freshman was a computer data processing class. Using statistical programs such as R and SAS, I was able to dig into statistical principles more without being distracted by complicated calculations. I had fun realizing the principles through coding, so I studied them with interest and enthusiasm enough to work in the class. I gained confidence from the class, studied Python and VBA additionally by myself, and learned how to use R markdowns and how to implement various codes such as regular expressions, and steadily developed statistical analysis and coding skills. For me, LG CNS is the perfect company to demonstrate my capabilities and develop related skills. I got to know the company through my motivation to work as an intern at the headquarters, and I thought it was a place where I could come up with ideas and analyze them using real data and work with a sense of reward for usefulness. At LG CNS, which plays a key role in developing technologies that are used most closely in daily life, such as transportation cards and Kakao Pay, I would like to participate in gaining meaningful insights and creating innovations through a large amount of data. In particular, I would like to work on the smart factory and smart logistics business promoted by the headquarters. I think this business will lead the 4th industrial era by connecting industries through digital platforms. We will conduct meaningful analysis that helps various industries by using data from companies in various industries that are difficult to access. I would like to participate in the SW Boot Camp and learn the languages such as JAVA and C in depth to get an opportunity to practice with real big data. After joining the company, I will become an expert in the field of smart factories by developing my ability as a data expert by learning IT skills, reflecting intuition in the analysis. I feel proud in the process of deriving meaning from logically designed analysis results, rather than simply processing and inserting data into a set statistical analysis framework. In order to develop my expertise as a data analyst, I learned various methods of accessing data and interpreting results by looking at examples of analysis, and proceeded with the project myself. By comparing the performance of different models in my major class, I have gained experience by making a demand forecasting model using a random forest model and receiving feedback from the professor in Seoul. Last semester, I participated in the panel big data analysis competition held by our school and carried out the project. Using apps and credit card payment data of 115,854 respondents, the analysis was conducted on the subject of consumption patterns of grooming people (male interested in beauty). In the process, we had to create variables that represent the degree of interest in beauty for each respondent. We came up with a method to measure the degree of interest in beauty by assigning the reciprocal of the frequency as the importance to each cosmetic item and scoring it. Through tree model, logistic regression, and correlation analysis, we were able to get cosmetics marketing insights from men and received the second prize. We can see data from a new perspective and analyze it with creativity. \"Confidence in coding developed by challenging various tools.\" \"I am passionate about coding tools. I used to voluntarily learn and incorporate other programs based on my R and SAS skills during statistical analysis as well as other activities. When I was working as the vice chairman of the financial association, I taught other students how to find bond prices using Python and how to run Monte Carlo simulations. When I was an intern at an insurance company, I learned the VBA by myself and automated repetitive tasks after seeing that I used Excel for most of my tasks. As such, I have the ability to acquire tools and computer languages for new practical tasks based on the spirit of challenge.\"?????????????????????????????????????????????????????????\"', '1'], ['I have developed an attitude that not only considers \"converged thinking that appears to be an action,\" but also puts it into action. It was based on the strong encouragement of my parents to \\'try anything because it is okay to fail\\' from an early age. It was a big difference in that I could turn what anyone could think into action. When I was a bachelor\\'s degree, I majored in computer engineering and thought a lot about what value IT technology can create when it converges with other fields. Furthermore, I have actively developed convergent thinking by directly transferring it to project execution. First, I have experience in developing an \\'IoT-based facility failure prediction system\\' in connection with the manufacturing industry with OOO in a graduation project conducted through industry-academia cooperation. I was usually interested in smart factories, so I proposed it first after writing the plan, and among them, I developed my expertise by being in charge of sensor value design, DB design, and construction. Second, in order to revitalize the traditional market, I took a Capstone design course that allows IT projects on the subject of freedom. It was very interesting to try to apply IT technology by finding problems and seeing and feeling in the market. I developed \\'IoT-based traffic assistance device\\' to improve traffic problems in the market, and I was in charge of developing software installed on the device. I will try to make my experience of convergent thinking and professionalism in translating into these actions lead to an active work attitude even in Nautilus efficiency,\"\" Embedded Software,\"\" Algorithm,\" and Embedded Software\" are two keywords that express the competence that I have developed. While taking a creative engineering design course, I became interested in Embedded Software. Through Mindstorm programming using NXC, I created robots and installed software. It was very interesting to see real robots in action, not the monitor console screen. This interest led to an interest in IoT as I went up to the senior level. Not only programming languages but also network and DB knowledge were necessary, so I took data communication, DB system, and artificial intelligence courses. I have experience in developing pet behavior detection platform and pot monitoring system based on small modules as two representative projects using IoT. Through this project, I was able to gain deep knowledge about Raspberry Pi and Arduino, which are ultra-small PCs. In addition, I judged that knowledge and utilization of \\'alternative algorithms\\' are the most important for programming efficiency. Therefore, until recently, I have taken state-funded education for training algorithm-based Java developers, learned privately through algorithm learning sites, and supplemented my skills. As the two competencies I have developed are essential elements for developing software and solutions that will fit into various machines owned by Nautilus Hyosung, I will quickly adapt to increase technological competitiveness. Strengthen comprehensive self-banking solutions,\"\" I applied because I wanted to make a leap to become a comprehensive self-banking solution company that Nautilus Hyosung aims for. Currently, Nautilus Hyosung is experiencing various opportunities and changes due to the emergence of Internet-only banks and the decrease in branches of existing banks. At this point, I was able to see its positive attitude toward R&D by seeing the increase in exports of \\'NBS\\', a self-banking solution, and the development of various solutions to realize unmanned banks. When I was a bachelor\\'s degree, I was interested in embedded software and worked on a number of IoT-related projects. I judged that the Nautilus\\'s effectiveness, which requires the harmony of ATMs and solutions, could be the best of my ability. We will focus on accelerating the smart ATM business further and strengthening our technological prowess to match the increase in non-face-to-face channels. \"Increase and expand business agreements\" As a way to increase the market competitiveness of the business unit, the government should push for the expansion of business agreements with the banking sector and the introduction of AI services in Korea. If additional authorization of Internet-only banks is implemented within this year, the number of non-face-to-face channels will increase further. It is necessary to expand services that can be solved with ATMs and accelerate the spread of smart ATM devices by installing interactive AI services. Overseas, we need to expand our business activities more actively. As our technology is being recognized by expanding the export of \\'NBS\\', a self-banking solution, it is necessary to strengthen our business strategy to find a market that can enter the market.\"???,,,,', '1'], ['One of the things I wanted to achieve intensely was to enter graduate school and do convergence research. The biggest reason I wanted to do convergence research was that I wanted to do something valuable using my IT knowledge. I majored in in information and communication electronics, but I was tired of simply improving the performance of technology. It is because core technology is included in all products and services, but technology eventually develops for people. Sometimes, when I see services released to show off new technologies, I feel sorry for the idea that users did not consider at all. Although the 4th Industrial Revolution has not been clearly defined yet, it is developing into a hyper-connected, hyper-intelligent society, so it is necessary to understand people from the research stage. Just like studying human brains at Midas IT, I also immersed myself in convergence research by studying HCI, human behavior and user experiences. There are two examples of improving the waiting time for children\\'s hospitals at OO Hospital, which produced good results while conducting convergence research, and curating services at the Gyeonggi Museum. The first was to organize a human+engineer and a humanian team with a lab colleagues and propose cooperation to the hospital by e-mail. It has been a very difficult task that has not been solved for decades, even though many hospitals recognize that waiting time is much longer than the treatment time. It was impossible to increase the number of doctors or reduce the number of people treated per day due to a problem that was directly connected to the hospital\\'s profits. Recognizing the limitation that physical time could not be shortened, I looked at it from a psychological perspective. As I constantly interviewed, empathized, and communicated with nurses, patients, and guardians, I began to see one or two clues to the study, and considering that all patients are children, I was able to develop analog art tools and digital fairy tales that can forget boredom through fun. We designed a scenario and are currently developing a demo so that if children input their own drawings through a scanner, it can become a fairy tale story on the TV in the waiting room. It is too early to say that it was completely successful because it has not yet been commercialized, but I expect it to respond well because it reflected all the feelings felt in the field during the demo development process. The second is the case of launching a smart curating service using the Bluetooth function and beacon of a smartphone when viewing the permanent exhibition at the OOO Museum. As an industry-academia joint project, I formed a team with one company and majors in planning, design, and participated, and I was able to communicate in a multidisciplinary team to experience the design process and learn design sensibilities. I was responsible for researching indoor location-based algorithms. Initially, Bluetooth signals were used to implement them, but the accuracy of wireless signals was low indoors for actual commercialization services. As a result of the test, the service we wanted was not properly performed, and other methods were needed for better performance. After much consideration, we implemented the algorithm by fusing relatively accurate magnetic field sensors, and we were able to solve some of the problems in terms of accuracy. Through this, we published a number of papers and successfully applied for two patents. I learned that commercialization services are very difficult, unlike projects that were simply developed as demonstrations at schools. The final test process also took a considerable amount of time because errors can lead to customer loss. It was the most meaningful time because I was able to indirectly experience the process from a company like Midas IT to the creation of a new service, and I could also sympathize with the fact that many people\\'s efforts follow behind it. I think the biggest reason why I was able to solve the problem in the above two cases was the rendezvous between various majors. Due to the nature of the laboratory, humanities, design, and engineering majors were able to achieve outstanding results through constant communication and collaboration. Even though I am an engineer, I was able to communicate with my team members more easily because I have discovered problems while observing people with them and have experienced field interviews. I am proud that my experience of designing every process from problem recognition to solution can help me create values even as a member of Midas IT. Based on the collaboration and convergence capabilities I have acquired over the past two years, I would like to create new customer value that combines technology and business with Midas IT. I believe that the practical competencies in the web solution technology field are four in the order of importance: collaboration competencies, convergence competencies, problem solving competencies, and professional technology competencies. Among them, I would like to give 88 out of 100 points for my competency (calculation basis: collaboration competency (30%), convergence competency (30%) - 95 points, problem solving competency (20%) - 85 points, professional technology competency (20%) - 70 points, 95*0.3 + 95*0.3 + 85*0.2 + 70*0.2 = 88) Collaboration competency I have been working as an OOOO since March 2016 until now. The biggest reason I feel proud and attached to being a member of OOOO is that I am conducting human-centered research based on technology. The human-friendly HCI field pursued by OOOO is considered an essential study in the Fourth Industrial Revolution, but it is recognized as a very unfamiliar field as it is in its early stages in Korea. OOOO has the advantage of having the research ability of humanities, design, and engineering majors to design every process from problem recognition to solutions to create the best synergy. As a researcher for OOOO\\'s master\\'s program over the past year, I managed 600 million won in assignment costs alone, and I was able to achieve excellent results in annual evaluation by using it efficiently. In addition, I was able to enjoy the honor of jointly winning the Popularity Award and the Special Award by prototyping a walking aid that corrects my posture at the Medical Hackathon 2016 held at OOOO Hospital. In addition, we made great efforts to develop the department through the launch of application services and patent applications through industry-academia cooperation.Convergence Competency I was able to experience the design process and learn about the design sensibility at OO Design School. It may be ironic that engineering majors study design, but I studied UX design because I thought it would be difficult to create good products without going through UX design process that recognizes humanities value judgment and emotions rather than technology in the upcoming Fourth Industrial Revolution. With the convergence of development skills learned in the undergraduate Department of Information and Communication Electronics Engineering with research in the HCI and UX fields at the graduate school, we are ready for the upcoming fourth industrial revolution. Currently, even in the laboratory, we are used to constantly creating new things through multidisciplinary convergence research, and we are carrying out the First Mover mission of ICT, emotion, and design convergence technology that draws out social and human communication skills according to the changing demand of the times based on user experience rather than technology-oriented. I saw many students standing in line in the elevator on the way to the problem-solving competency class and looked for ways to increase the utilization rate of stairs. I thought that if I could play the piano sound when climbing the stairs, it would increase the use of stairs and reduce elevator congestion. When I investigated previous studies and cases, there was a case where it was manufactured using a pressure sensor. It was judged that the use of a pressure sensor could cause frequent breakdowns when many people used it, and it was differentiated into a non-contact method and a low unit price infrared sensor in order to use it for a long time without residual failure. An academic small meeting conducted a project to solve the problem. A sensor detected human feet and a scale suitable for each step was outputted through a speaker. Troubleshooting by electric power occurred during the output process, but the cause was found through a systematic approach and analysis and it was solved through ground reorganization. It was memorable for a long time that it was installed on campus for 3 days to receive the attention of students and professors, and that it resolved the inconvenience that began with a sense of improvement. Above all, it is an unforgettable memory that the project solved the inconvenience in life. In addition, in the OOO study, I remember getting on the subway line 1 directly, measuring carbon dioxide, and counting the number of passengers in the cabin, one by one. We were able to analyze the correlation between the amount of carbon dioxide and people, and achieve the results of exhibiting at the OOO Demo Session in Germany. I became interested in AI through a professional technology competency webinar, and I have experience in presenting a paper to the Korea OOO Association using IBM Watson API Demo. The thesis topic is \"OOO,\" and we experimented with Watson\\'s Visual Recognition, Text to Speech Demo, which shows a high recognition rate. Recently, I am studying deep learning, one of the fields of artificial intelligence, and I am also studying various classification algorithms through supporting statistics and data mining classes. Using open sources, I created AI Amazon Alexa with Raspberry Pi, microphone, and speaker, and implemented a stock price prediction program. In the \"Development and validation of interactive language learning device\" project, we are testing an object recognition application demo that learned 1000 objects, and we are reading related papers to find ways to increase the recognition rate. Since June, I have participated in the research project \"Study for enhancement performance of robustness and precision in fingerprinting and PDR technologies for indoor location estimation\" to collect and analyze data. As we are currently in the early stages of research, we are looking for related studies, and the ultimate goal is to estimate the indoor location more accurately and robustly through deep learning of wireless signals. Although I have not been able to highly evaluate my professional competence as I have just started studying AI, I will confidently promise that I will be reborn as a talented person who will lead the company in the distant future if we grow together and build up our capabilities at Midas IT.\",,,,', '1'], ['I thought that we should deepen our knowledge through active practical activities that accurately learn and apply what we have learned. I was in charge of planning and coding at the 2016 OOOO Challenge app development competition organized by OOO last year. As a result of brainstorming as a team of five people, we decided to create an app that provides a service that people with mental problems can easily share their concerns and wrote a plan. As a result, I was able to pass the preliminary round and advance to the finals. From this period on, I was in charge of coding for producing apps and implemented UI/UX and functions. Unfortunately, however, I was eliminated from the finals and the activities were suspended, so I was unable to complete them. Through this competition, I have acquired overall theories and skills in app production, and my project planning methods and ideas have improved a lot. In addition, at the \\'IT Hope School with Tmax Soft\\', I learned the language necessary for website production such as HTML, CSS, and JavaScript to conduct individual and group projects. While thinking about what kind of homepage I should make for my personal project, I made a self-introduction homepage that briefly introduces me, and in the group project, I made a roulette homepage that helps me select and organize on duty. After producing the homepage, not only did my web production skills improve, but also my presentation skills improved by giving a presentation in front of the CEO and other executives and staff members. Through this experience, I have a lot to learn from failures and have realized that active activities are a good way to develop expertise. \"A person who achieves his or her goals\" I was told by a teacher at the youth training center in front of the school called the \"International OOO Awards.\" This program is an international self-growth program that enables you to realize your potential through four activities: physical training, self-development, volunteer work and exploration, and to have life skills that change you, your community and your country. I started at the lowest level in this activity, the Dong (six months). My goal was to build a web page for self-development, build muscles for physical training, organize library books for volunteer activities, and set up the last expedition activity as the main pillar of Baekdudaegan. I could easily finish my self-development and volunteer activities because I had been doing it steadily, but I ran after only the final goal without making any specific plans for physical training and exploration activities. When the teacher saw me like this, he told me that I ran only after the final goal, and that I had no choice but to hate doing activities that I did not like. Having identified the problem, I found and selected my favorite activities and made a detailed plan. For physical training activities, I planned to do exercises by part, such as leg exercise for one day and chest exercise for one day, and for exploration, I planned to climb three mountains for a total of three nights and four days. As a result of this detailed plan and activities, I successfully completed all activities, passed the reward screening, and obtained the head of the Dong. It was never easy to set a goal and put it into action while doing this activity, but I was able to successfully finish it because of my parents and teachers who supported me by my side, and gained confidence in achieving the goal.\"\"Hit it and pierce it, and it will work if you go through difficulties.\"\"\" In my second year of high school, there was an English presentation competition where I gave a presentation in English about my major. The given time was only 10 days. Since it had to be completed in a short period of time, the key was how to capture the eyes and ears of listeners. For the first five days, I practiced in front of my friends and family for about two days, just like my friends who opened the event, where I selected themes, produced presentation materials, and practiced presentation on the level of reading materials while standing still. However, less than half of the presentation, everyone commented, \"I was less concentrated and nervous.\" I almost fell into frustration with the first competition coming up, but I decided to do it on my own soon and decided to do it myself. After watching my presentation on a video, I thought it would be better to proceed with the presentation in a talk method that communicates with listeners rather than a hard one. On the day of the competition, I performed a differentiated stage from the participants who only made arm gestures or stood still and presented. As a result, I was able to successfully finish my presentation without getting nervous on stage, and although it was an incentive award, I received a better evaluation than other teams in terms of presentation. While preparing for the competition, I was pushed out of time and had a hard time in situations where I had to bump into anything, but I was able to develop my creativity, develop the perseverance to manage through difficulties, and learn how not to be nervous in front of many people. \"The driving force behind teamwork is active communication.\" When I was a freshman, I participated in a program called OOO, a middleware development company, for about eight months from April to December, to create and provide websites for executives and employees. This program is a mission where four people form a group and implement websites related to a topic based on the web site production techniques learned during one semester. With the expectation that all the members of the group would create a website, they initially presented a lot of ideas and showed their positive attitude. However, as each member demanded more, I couldn\\'t concentrate and started to become lazy in everything. As a result, the conflict worsened because the members of the team had to make each other\\'s way and because they acted selfishly, saying that they should make it their own way. Due to the nature of the project where teamwork is important, a big crisis has come to our group. As a team leader, I invited each member of the team to listen to and sympathize with the upset, pointed out the wrong parts, and broke down the walls of my mind to resolve the conflict one by one. In addition, I decided to create a roulette site where I was in charge of program production, one in planning, one in debugging, and one in design, and choose the role that I could best play.Doing so made the project faster and faster, and the team members showed their positive side as they did in the beginning. Finally, our group completed the project and won the valuable result of being second out of five groups. While working on this project project, I have gained confidence that whatever difficulties arise, I can overcome conflicts and resolve them through communication and consideration.\"???,,,', '1'], ['\"Man Who Doesn\\'t Give Up\" I am interested in business activities of a company, so I majored in business administration multiple times. The difficulty while taking the business administration class was a lack of basic knowledge. In particular, the trade class was most difficult because various knowledge such as terminology, customs clearance, transportation, payment, etc. were required, and in addition, the grades of the semester were evaluated as trade project performance. The project was a personal task of discovering competitive items in Korea and selling them to overseas buyers under the theme of \\'Finding Overseas Buyers.\\' It was not easy for me, which was not familiar with trade, to compete with business students. So I decided to bump into it first. First of all, I had a lot of conversations with a Chinese exchange student who was helping me adjust to life in Korea to get an idea. At that time, the smartphone trend was in full swing in China, and since the Chinese people liked gold, I selected a gold decorated smartphone case as an item. Due to my lack of knowledge and experience in trade, I had continuous consultation with the professor. After seeing my enthusiastic attitude, I introduced him to a professor who was engaged in the trade business, and he introduced me to another acquaintance, so I could get a lot of advice on the project. It was also my first time looking for a company, so I recklessly ran around and visited several companies, and after several failures, I was able to find a company called \"DDPOP\" and get an offer at a reasonable price. Later, with the help of a Chinese friend in Chinese, I was able to export three kinds of products to a company using Alibaba in China. As a result, I succeeded in the project and became the most notable student in this class after the presentation. Through this experience, I learned that I can overcome any unfamiliar field as long as I have the spirit of challenge and the driving force to support it. \"What the Youngest Can Do\" The organization that I feel most affiliated with is the Early Football Association, which has been active for seven years. The reason is that I have been active since the foundation of the soccer association until now, and I only like soccer and meet people every week. The most memorable experience was the separation of teams. Eunpyeong New Town FC has members of various ages from their 20s to 50s. As many diverse people gathered, they had different expectations for the soccer team. Some members wanted to play against talented teams and compete in competitions, while others wanted to play fairly and exercise without injury. Opinions were divided, and eventually, the young members who wanted to win the game withdrew from the soccer team. It was very painful because I relied on them when I was in trouble and could no longer see them with my brothers who have been with me for a long time. I decided that this was a matter of affection and communication, and I didn\\'t want to repeat the same experience again. After much thought about what kind of role I could play as the youngest member of the soccer team, I decided that I could play two roles. First, I started working as vice president by helping the general manager. I volunteered to recruit the opposing team to notify the game on the cafe, and contacted the members. In addition, I led by example to carry operation boards and water before the game starts and clean up the trash after the game. Second, I created a place to communicate. I tried to revitalize the cafe by promoting a picnic where I could play soccer and eat with my family, and posting humor and reviews of the game on the soccer team\\'s cafe every week. The members were proud that the youngest has a great love for the soccer team. Now, we have become a soccer team full of love, sharing each other\\'s updates at cafes and having a meal with family once a month. I think our hearts are connected. I promise to become a new employee who truly communicates and thinks about what can be done for the organization. \"No innovation, No Future\" In-school software engineering lab carried out the national task of \\'Rebuilding S/W Architecture\\'. Despite the successful completion of the research by developing a solution, it is my great pride to improve the solution for better performance and to publish this process as a paper in an international journal. The widely used template-based web application (TWA) method has the advantage of code management through modularization, but there is a problem that data that does not require renewal is transmitted and processed on the server. I developed a solution using the Azax technology and the PJAX framework, and through this, I was able to successfully complete the study. However, while conducting performance tests after developing the solution, I was able to find that the solution using the framework has large capacity and is difficult to use. So, I decided to form a team with one of my colleagues to create a lightweight and convenient solution. I had to develop a solution and live undergraduate life at the same time, so I had to pay a lot of attention to time management such as assignments, team meetings, and test periods. Through the two-month development period and more than 20 improvements, the solution was completed without a framework. Through this, we were able to complete a solution that converts the TWA method into a single-page web application (SPA) method that updates only the parts that are needed. In addition, by organizing this process, we have achieved great results in publishing a paper in the COMPSAC organized by IEEE in 2013. \"No innovation, No Future\" I think there will be no further development without new attempts and challenges. Through constant worries and actions, I will grow into an engineer who provides the highest quality service.\",,,,', '1'], ['[The Core of Future Technology, IoT] I heard that LG CNS has recently obtained the IOT International Standard Certification \\'oneM2M\\' and CoAP Protocol interworking compatibility certification for the first time in the IT service industry. I first got introduced to the CoAP technology through the undergraduate graduation project and became interested in IOT, so I developed the graduation project using the beacon technology. IOT technology is the center of the future industry and I think it can make human life richer. My dream is to develop technology that people can make more convenient by using less labor through IOT. LG CNS is investing a lot to develop IOT technology, such as smart robots for cleaning server facilities and developing set-top boxes for smart home implementation. I think they are going the same way as me in developing services for people. I want to build my LG WAY at LG CNS, which puts customer value first. I once participated in a project competition organized by the CEST Embedded Research Institute as a team with my friends. The theme is \"Smart Bicycle Cluster Driving Using BLE Beacons,\" which measures the current coordinates of electric bicycles and the distance between the bicycles through GPS and beacon correction algorithms, and displays the bicycle\\'s location on the mobile phone application. Arduino has implemented an automatic speed control function that slows down electric bicycles when the distance between the bicycles is closer than the reference distance and increases their speed when the distance is getting farther. In recognition of the achievements after the completion of the project, I interned at the institute during the winter vacation of the third grade. The institute focused on the ZigBee-based electronic price indicator (ESL) project and supplied it to hypermarkets and department stores. I worked to update the server DB of the ESL program and test bugs, and in the process, I learned more about the structure of the ESL program.\" [Building a Perfect Smart Farm System] LG CNS has learned that it plans to complete the smart farm by investing heavily in the Saemangeum foothold by 2022. Agriculture is an inseparable entity in our lives. However, as the number of people engaged in agriculture is decreasing and the labor force is decreasing, I think smart farm technology is essential. I will take over as the ITP of LG CNS and contribute to the establishment of a perfect smart farm system. Furthermore, in 10 years, I will try to stabilize and expand the smart farm system in Saemangeum Reclamation Area to build a vast smart farm like Agreport A7 area in the Netherlands. To this end, we will learn the technologies necessary for smart farm automation, such as automatic temperature control system using IOT technology, water supply system, and cultivation quality analysis system. And we will make LG the leading in the smart farm field by supplementing the automation technology for harvesting and packaging, which is still insufficient technology in terms of customer satisfaction.\"???????????????,,,,', '1'], ['[Game is named] Since I was young, I have always been interested in games, and I have been playing them continuously, to the extent that most famous games in Korea have been played. My parents didn\\'t let me play games, saying they weren\\'t helpful for my soul, and I used to play them secretly all the time. Usually, people consider games to be bad, but some people get energized by them. A game is defined by how the user uses them. I wanted to give people a boost through games because I thought they were a place to live and get people energized, so I applied for game server programming. [Let the World Play with Us!] My favorite phrase from NHN Ent.\\'s four introductions is \\'Let the World Play with Us!\\' Knowing the fun and joy of games, and having people who know them make games and sharing them with the wider world and greater fun for more people. I have a goal similar to mine that I want to revitalize through games, so I applied because I think just working for NHN Ent. would be a grateful thing. In addition, I think I can grow through the company by encouraging new education, sharing skills, and establishing a welfare system for people. \"My favorite game is Dungeon & Fighter.\" Dunpa is an online action RPG game based on a solid worldview and exciting stories. It is based on a dungeon that users farm, and a special content dungeon, a multi-user participate to complete, is held every specific day of the week. The difficulty of dungeon is properly set until a beginner becomes a skilled worker, and along with that, avatar content that users can enjoy is well established. Although Dunpa\\'s final content is \\'Luke Reid,\\' it shows strength in avatar content enough for users to jokingly call it \\'look+duck,\\' and stands out even more because there are many characters to choose from. However, there are many complaints from users because the number of jobs is too large and the recent update does not seem to consider the user, causing complaints from users. In addition, the overall system is based on probability, including the \\'hell party\\'s\\' epic item drop rate to get good equipment, and is evaluated as a \\'lucky game\\'. It is a game that weighs between effort and luck, but it is good to play with pleasure and has a large number of users, so it is appropriate to play together. In particular, the specifications of characters that are important in RPG games are well-formed into several stages, so I can say that it is a good RPG game.\"\"Pixelcube hopes to play games that are simple, but require brains or quickness. I like those games, too, and I enjoy playing games like Sudoku, Square Nemo, and Janggi. Complex games like RPG and FPS are fun, but I think simple games like this should be well-made and entertaining. Just as the foundation is the most important when building a house, the market for games needs to be well-developed if the basic games are well-organized. It is also good for the market to use such simple games to prevent dementia in an aging modern society. I think it\\'s important to make simple games in many aspects like this, so I hope to join Pixelcube.\",,,,', '1'], ['In college, I participated in a contest and developed a score recognition program with the goal of winning an award. In college, I participated in a contest and produced a game with the goal of winning an award. The assignment was to provide convenience to beginners or advanced users who wanted to learn by recognizing guitar scores through video processing and making it easier to store and modify. Sometimes, when friends learn how to play the guitar, they forget the exact guitar code after about a year. So, through this APP, they can view their own music anywhere they are on mobile devices. However, despite our efforts, we received a lot of criticism in the final evaluation. The reason was that we wanted to complete the project only with coding technology, but the UI/UX part used by users was not good. So, we found out that we needed to cooperate with people in various fields. So, we proposed to collaborate with a design department that the club had not promoted before. There was also a lot of opposition from colleagues who were burdened with collaboration with other departments. It seemed that there was a fear of recognition because it was a new attempt. However, when I finished the project, I thought it would give everyone a great spirit of challenge. So I first approached the opposing team members and persuaded them by telling them why collaboration is necessary. And I built a teamwork through many conversations. With these actions, I made plans myself and made and pushed forward with detailed schedules. So I had a lot of conversations with the members of the club, and I was able to get positive support from the opposing team members. In the end, I received the Best Teamwork Award at the Samsung SW Competition due to favorable reviews in design and collaboration among team members. From this experience, I was able to see that passion for a goal and collaboration with people in other fields are important when working on a project. Even after joining SK C&C, I will develop a lot of technical skills so that I won\\'t give up.\" \"In college, I participated in the energy hackathon, developed the fintech program, engaged in the Imagine Cup, and engaged in the score recognition program to be creative,\"\" \"Energy hackathon: Thinking about where to go.\" \"I went out to the hackathon and did not give up even when I encountered time limits, but I had the experience of showing passion without giving up. The biggest problem was the short production time when I participated in the hackathon. Usually, when we produce a program, it takes a long time, but we struggled with the production idea in two days. It\\'s because no matter how good an idea comes out, it\\'s a failure if you don\\'t complete it in two days. So, after a lot of thinking with my team members, I decided on the idea. It was to create a Fin Tech APP that could plan electricity use by allowing you to check your electricity usage in advance with a smartphone. However, since a lot of fintech technologies have already been released, the surrounding people gave negative opinions. So we thought differently and thought about whether it was convenient to use it from a user\\'s point of view, even though it was already made. Young people usually use smart devices well, but my grandmother and grandfather came up with something that was still difficult and uncomfortable for the blind. So, for the elderly and the visually impaired who do not use electronic devices well, we decided to add an ARS function to implement a function that can inform them of the amount of money they have used by voice according to their current power. I made the Android part and let the team members use their respective APIs to make it. I shared the roles and proceeded according to the limited time. At first, I thought it would be difficult, but I didn\\'t give up and tried hard, and it was completed in a short time and received the Energy Hackathon. Although it was a short time, I was able to learn a lot because I came up with an idea that fit the topic and divided the tasks according to the period and won first place. From now on, I will maintain this persistence and try to complete it without giving up despite many difficulties even after joining SK C&C.\"\", \"Get an OCP\" I took a DB class when I was a third grader. But I was most interested in this class than any other subject. Data base is an important technology that goes into all programs. This is because even a small program needs to build a DB to take information and use it again. So I acquired OCP DBA-10g to gain DB knowledge. I have been studying database faithfully, but I also needed to study other patterns to prepare for OCP. As I developed the POS System, I increased the convenience and safety of users by analyzing User Data and showing it as Chart. I was able to pass the test based on the DB knowledge I gained by creating ADO.NET POS with high safety using Oracle myself. As I engaged in various internship activities, I gained many experiences like MySQL. I think OCP DBA-10g has granted me the qualification to be recognized anywhere in the world, not limited to Korea. If you know a solid DB as an IT expert, it is easy to understand the technology to process information. I am still posting seminars I conducted on YouTube to gain strong expertise and gaining DB knowledge through SK T Academy. I will join SK C&C and sublimate various problems into my expertise.\" \"Experience of preparing for a contest with people around me while working as a club in college,\" \"People who know responsibility and act on a team project.\" \"Responsibility and cooperation are important. I learned that when I started a club when I was in college. When I first joined an academic club, I was preparing for a contest. But I thought the contest was not about solving problems alone like a school assignment, but about solving problems with my team members.So I thought I should show better performance to my juniors. So, the club held a seminar for 10 juniors every week, and when I was working on the project, I arrived at the appointment earlier than anyone else to prepare for the project. And while it is important to be trusted by others through actions, I think it is also important to be trusted by others with the heart, so I often talked with the club members with the same mindset. In addition, while preparing for the Imagine Cup and the Capstone Design Energy Hackathon, I became the leader of the team, felt responsible for the project, conducted it, and communicated with my team members. As a result, I was able to take the position of the head of education within the club and received the Best Teamwork Award at the Samsung Electronics Competition. These experiences can create rapid organizational convergence and synergy after joining the company.\",,,,', '1'], [\"-While working as a personalized service intern, I built a web service that records and manages it as 'my to-do', a personalized service. There are many TODO services, but now many people make a lot of things to do through job studies, but I tried to solve the inconvenience of not sharing the schedule due to spatial constraints by making a TODO list. And I started with the mind of actually producing it using everything I learned. The project proceeded with a personal project. First of all, I made a statement of demand and thought about the DB structure, and I kept thinking about what I needed. I started making it using Spring Boot, and the DB used MySQL. And I applied the method of using Nested Results for Collection with the Mapper of MyBatis. And for CI, Jenkins made it easier to manage continuously. And I wrote a cleaner code using coding conversion, and I made them test the code of the service sector through UnitTest. And I tried to develop the service sector more safely using transactions. But there were also difficulties that I had while proceeding. Among the input types supported by Chrome, it was a problem when receiving objects directly from Spring using datetime-local. There was no problem when I received Date or Time, but an error occurred when I used datetime-local. When I debugged it in detail, the form of datetime-local was yyy-MM-dd Thh:mm, and special characters entered the middle, so it could not be automatically substituted. So I used Converter to convert the received inputs to Date. On the contrary, when I took them from DB and sent them to JSP, I easily solved them using JSTL. I have previous experience of winning them through hackathon or contests. However, I thought this project was the best project because I thought about the technology and safety and efficiency that I applied to the best practice. Usually, contests only see ideas and execution, but as I was working on this project, I thought about Clean Code. Even if it is implemented, I found out which data structure is appropriate to use for each object and which part has changed and requires understanding of API. Unlike students, in practice, a project is not carried out by one person but by several people. Therefore, I think we need someone who has experience in CI and thinks about algorithms and safe codes. Therefore, I think I can grow in TicketMonster. Even if I join TicketMonster in the future, I will be an applicant who writes while thinking about even a line of code.?????????\", '1'], ['-The field I am most interested in in server development is web server development. This is because programs that communicate with other programs or import information through communication to a server can operate more functions than a single program. Since the most people are active on a platform called the web, I thought that many services could be provided and more services were required in the future. As for my experience in the web server field, while working as an intern, I built a web service that records and manages as a personalized service called \\'My to-do\\'. Although there are many TODO services, many people currently create a lot of things to do through job studies, but we tried to solve the inconvenience of not sharing their schedules due to spatial constraints by creating a TODO list. And I started with the mindset of actually producing using everything I learned. The project proceeded as a personal project. First of all, I made a statement of demand and thought about the DB structure, and I kept thinking about the necessary parts. I started making it using Spring Boot, and the DB used MySQL. And I applied the method of using Nested Results for Collection with MyBatis\\' Mapper. And I made it easier to manage continuously with Jenkins for CI. And I wrote a cleaner code using coding conversion, and I had UnitTest test the code for the service sector. And I tried to make the service sector more secure by using transactions. I\\'ve won through hackathon or contests before. But I thought this project was the best one because I thought about the technology and safety and efficiency that I applied to the practice. Usually, contests only see ideas and execution, but as I was working on this project, I came to think about Clean Code. Even if implemented, I found out which data structure was appropriate for each object, and what parts were changed when it was changed to Java 8, and I needed to understand the API. Unlike students, in practice, a project is not conducted alone, but multiple people. Therefore, I think we need someone who has experience in CI and thinks about algorithms and safe codes. Therefore, I think I am a person who can grow even after joining the company. Even if I join the company in the future, I will become an applicant who writes while thinking about even one line of code.\"- TODO Personalization Service 1) Progress period: 2016.12~2017.02) Main contents: Establishment of a web service that records and manages the personalization service as \\'My Halil\\'. 3) What I contributed: Development of servers based on Spring Framework 4) Skill or knowledge using Spring Boot, MySQL, MyBatis, JSP, Jackie, JUnit, Jenkins 5) Results/Performance: Development process experience, production of Java-based web environment. - 2016 Energy Hackathon 1) Progress period: 2016.02) Main contents: Producing an energy-saving APP that can be used by checking the usage of electricity in advance 3) Contributing points: APP Development 4) Skills or knowledge used: Google TTS, Newtone API, EnerTalk API, Android 5) Results/Performance: Grand Prize - OOOO Home Appliance Department App Production and Participation in Research (Smart Washer APP) 1) Progress period: 2015.03 to 2015.06 2) Main contents: Participating in the production of APP conducted by OOOO\\'s Home Appliance Department in the first half of 2015 3) Contributing points: Producing washing machine information and data usage application using NFC. 4) Knowledge: Using Android application and weather API. 5) Results/Achievements: Positive reviews during the internship process, experience in the development process, experience in implementing various Android functions - Participation in Microsoft ImageCup (Development of Data Driver System) 1) Progress period: 2014.2 - 2014.04 2) Main contents: Making a game platform using the Data Driver system 3) What I contributed to: Making the platform 4) The skill or knowledge I used: Data Driver System, XML, C#, XNA 4.05) Results/Achievements: Keimyung University won outstanding prize at the 2013 academic conference - Development of other learning APP through score recognition 1) Progress period: 2014.05 - 2014.08 2) Main contents: When a user takes a picture of a sheet music or selects it from an album, the appropriate guitar code is automatically generated, the accompaniment is played according to the code, and the user can check the way to pronounce the code. 3) What I contributed: Making the Android part. Each note was displayed on the screen so that the user could know how to pronounce it, and functions to modify, change, and delete the code were added. 4) Skill or knowledge used: android midi, Android SDK, Android NDK 5) Result/Performance: Best Teamwork Award in OOS/W -Development of education APP using Cocos2d-x) Period of progress: 2012.12 ~ 2013.0322) Main content: Making APP for early childhood education using Cocos2d-x 3) Developing multi platform (IOS, Android) by using Cocos2d-x 4) Skill or knowledge used: Cocos2d-X, Android NDK 5) Result/Performance: Keimyung University Award for Excellence in 2012 Academic Conference - Team Leader of Academic Club Education. 1) Period of progress: 2013.06 ~ 2013.12 2) Main content: Academic club activities.3) What I contributed: I held a major seminar for 10 juniors every week and proceeded with the project 4) Skill or knowledge used: JAVA, Android, c 5) Result/Performance: Training Team Leader,\"* Available languages: Java, C++, C#, HTML, SQL * Proficient languages: Java * Usage: 3 years of experience: OOO Technology Services intern, OOOO intern, multiple project usage: Android, Spring Framework * C++ Usage: 2 years of project: Cocos2d-x * SQL Usage: 3 years of experience: OOO Technology Services intern, OOOO intern, multiple project usage: MySQL, Oracle, SQLite HTML usage: less than 1 year\"???,,,,,', '1'], [\"[Developer who fills up if it is not enough and learns if it is not enough] I think that the development and operation job should be based on the knowledge of programming, so that you have the understanding of the system and the knowledge of the field you want to develop. In order to gain knowledge of programming, I took the database design course as I thought that the biggest role of the IT system was to store data and provide the information that users need. In addition, I learned Java, Oracle, JSP, etc. and experienced various projects through the completion of 600 hours of external training called the Big Data Manager course. [Experience of collaborating with people in various fields] While completing external training, I have experience working with people from the same department as well as people from other departments to work on projects and participate in competitions. Among them, when I participated in the DA design contest hosted by the Ministry of Science, ICT and Future Planning, four people from four departments with different data architecture design experiences and background knowledge formed a team, and there was a problem of frequent disagreement. However, the disagreement allowed me to see the problem from various perspectives and proceeded with the design by making use of each team member's strengths. [Happy : A month and a half trip to Europe] I took a leave of absence from college after finishing my third year and went on a backpacking trip to Europe to earn money on my own. While living in college, I thought that I really wanted to experience something different from other people's, so I decided to go on a backpacking trip to Europe. I convinced my parents that traveling alone was dangerous, and I worked part-time at a construction site in Suwon to save money. After work every day, I made plans by searching for travel information with my tired body, and I left for Paris, France on May 7. Due to my tight travel expenses, I often skipped meals and felt lonely by myself. The difference in language and culture also made the trip feel difficult. It was 'people' that made me overcome all these difficulties. [Sadness : Job Failure in the second half of the year] This may seem like a common thing because it is what most job seekers go through these days, but the saddest thing in my life was failing to get a job in the second half of last year. In the second half of last year, when I was in the second semester of my fourth year of college, I couldn't prepare much for employment due to graduation projects and outside classes. So I didn't have high expectations, and if I can't, I prepared for employment with the thought of doing it next time. However, one by one, I lost confidence as the documents fell and I failed the personality test, and as my friends around me got a job, I became impatient. Also, it was miserable to think that I didn't meet my parents' expectations. However, while preparing for recruitment in the first half of this year, I started studying algorithms and data structure, which I thought was insufficient, and I prepared step by step, and I found promising companies that I didn't know about last year. It was the saddest and least confident period, but rather, it was an opportunity to fill in the deficiencies and broaden my horizons, and I applied to Bartek Networks. If there is a shortage in Bartek Networks, I will become a professional and passionate developer with the mindset of actively filling in.\", '1'], ['I was into games when I was in middle and high school. I played many games, including Star, FIFA, and Sudden, and was one of the top five games on campus. That\\'s how I enjoyed playing games, so I entered the Department of Computer Engineering. As I entered the Department of Computer Engineering, I was attracted to programming while taking seminars and classes. As a program developer, it was rewarding that the code I made could help users, and I made it a profession. In particular, I thought that the development of individual programs by various customer groups such as PCs and mobiles would be diversified, and accordingly, I developed my practical skills through internship and club competitions to gain expertise in program development. #NotFearingFailureAttitudeI formed a team within the university. While I was signing a contract to lead a team to carry out a government project, I was also selected for the project, and I agonized over it. Many of the team members said, \"It\\'s hard to accomplish one task, but it\\'s hard to do two tasks at the same time, so let\\'s give up one.\" However, I persuaded each of the team members and planted enthusiasm and motivation, \"Nevertheless, we can do it.\" As a result of carrying out these two projects, I was able to receive two excellence awards at the end of the year. #Doing My Best When I first set up a team, I was very troubled because there was no server developer. I took the position of server developer with the responsibility to lead the team as a team leader. I had a hard time building, developing, and managing a server development environment through Linux books and Googling, but it was an opportunity to learn a lot about servers.\",\"\"#If the user conveniently chose the company as a \\'business\\' by leading the team through the code I wrote, I launched a service called \\'&\\'. I remember being very proud to see users use the services that came out of this business. It was an unforgettable experience to feel the flow of data in the programs I planned and designed, and to see users use them in exhibitions.\" My sister is currently working in the fashion industry. I have been watching the passion to become a fashion designer since I was young, and I can see how hard it is to work now because I am working hard day and night. I applied to Namyang International, a global clothing company, because I think it would not be more rewarding if the codes I wrote were helpful to those who work hard in fashion and became more convenient. I dream of becoming the best computer developer in #NamyangInternational. I entered the Department of Computer Science and learned data structure, operating system, Java, etc. When I was a second and third graders, I worked as an undergraduate assistant and worked on setting up, maintaining, and managing the development environment on more than 200 computers every semester. Based on this, I gained practical experience as an intern at an IT company for six months, and I was able to develop my planning, development, and collaboration skills through government projects and contests. I would like to contribute to developing into a global fashion company by demonstrating my IT skills at Namyang International. To this end, I will challenge the Linux Master Grade 1 certificate and LPIC to optimize my computer work at Namyang International.\",\"\" #I enjoy challenging myself to a new field. I like to learn and challenge new fields by being curious and active. For example, I joined the Taekwondo team and won several Taekwondo competitions during my school days. When I entered the university, I majored in OOO to make my name as a star, and I was able to experience many things that I have not experienced before through professors and friends. I think there is more progress if you think positively, want to know, want to learn, and experience courageously even if you fail than if you don\\'t and regret it.\"', '1'], ['IT technology is at the center of the rapidly changing world. It is not an exaggeration to say that the future direction depends on the hands of those who deal with IT technology. LG CNS\\'s actions to provide services to diverse customers based on these technologies are also the company that I will be with in the future. I believe that the logical thinking skills through mathematics, problem solving skills, and internship experience at a financial institution are essential experiences in developing a finance solution that LG CNS is leading. Through Python programming experience, I was able to find efficient and simple algorithms to achieve results, and also find appropriate libraries to write applicable codes for other fields. This has firmly established the need for programming and software, which is the biggest reason why I applied to LG CNS. While working as an intern at a global asset management solution company, I participated in the development of fund products that can yield absolute returns based on data from overseas funds. It was also very important to set up sophisticated algorithms because we needed data from all funds in the world to find information, and we had to be competitive under any circumstances. I was able to easily obtain the data by crawling the past 15 years\\' worth of data using Python, and also visualizing it to represent the trend of 1,890 funds over time. I also applied this code to create a foundation that can be applied to fields such as bonds, real estate, and derivatives. After these efforts, we successfully developed the product and received nearly 10 billion won in investment within two months of its launch. In the process, we were able to develop our work skills through programming.\"\"The next-generation financial system market, which began with the Fourth Industrial Revolution, is approaching our eyes. Based on Internet banks and fintech, the existing financial system is changing, and the role of LG CNS is becoming more important than anything else by introducing blockchain and new security solutions. I am trying to create a financial solution within LG CNS that leads to innovation in the financial business. With my experience in school education and asset management, I gained core knowledge of Banking and Finance, dealt with Big Data while working at an asset management solution company, and was able to provide Information & Analytics to our customers through Real-time Risk Mgmt. In the future, we intend to develop a new platform based on this domain knowledge in the next-generation channel and become a talented person who leads the LG CNS that leads the change in the global market, not a leader in Korea.\",,,,', '1'], ['While I was reading a C/C++ book after I was discharged from the military, I suddenly came up with the idea of a group chat app. I wanted to develop a program that could provide real services other than a school assignment, so I didn\\'t want to make it to a level that simply functions. But the problem was that I could only do C. But I didn\\'t hesitate to start. When I was developing Android, I wandered around for a long time not knowing why the relay server wasn\\'t connecting, and I had to learn Photoshop and Nine Patches so that the UI could respond to different resolutions. It took me a long time to write a simple query for the DB, and so did designing the communication protocol between the server and the client. Since most of the things I did for the first time, the progress was very slow due to different trials and errors. However, the more I developed it, the faster I developed it, and I didn\\'t have a hard time thinking of making the apps I had imagined. Eventually, after developing steadily for about five months, I was able to complete an app called D-Note. The experience of working day and night at that time became the basis of my ability today, and it was a great help in working on future projects. So now I know that when a problem arises, even if it\\'s a little bit difficult right now, if you try to solve it in the end, you will improve your skills and satisfaction with the amount of time you put into it. This was the foundation of my personality to be proactive in dealing with any issues that arise between developments.\" \"This is one of my two things that I was solving now!\" That\\'s what I used to say half-jokingly when I was on the intranet team, when I was asked if my coworkers were not going to bed. That\\'s how passionate and persistent I am that when an issue arises, I can\\'t rest peacefully without solving it. I had this characteristic because I enjoyed the series of processes of trying different ways and eventually finding the cause of the problem and solving it. Rather than just a one-dimensional solution to the problem, I tried to track and solve the issues that were even a little suspicious or open to improvement. So, when I tried to piece together puzzles one by one, analyzing sources one by one, looking for where the problem was, or asking for help from a reference or community, I\\'d forget to sleep until late at night and get into the problem. As a result, I developed a broader and more solid foundation and ability to cope with exceptions. Those experiences have come together to create who I am today, and have greatly influenced my belief that any problem can be solved with perseverance and effort. I still have that mindset unchanged, and I am confident that I will overcome any obstacles with my passion and perseverance. However, because of the personality of being immersed in one field, I couldn\\'t afford to do other favorite things. I also liked activities such as singing and leisure, but I often just kept thinking, \\'I\\'m going to do what I\\'m busy now and then.\\' These days, I am making an effort not only to develop, but also to have a more relaxed personality. This is because I think I can live as a developer for a long time only when I have a healthy mind to support me.\"\\'The closest software to people and Nexon\\' game are one of the closest software to people. Most people, regardless of age or sex, love games. As one of them, I also love games so much that when I was working on a project at school, I used to make mostly games. I made a snake game for two in my Android class and an airplane game in my openGL class. The game was always well received and the professor liked it. So, whenever I was making simple games, I often thought that I wanted to work in a field related to games. It is because making software that users like is a lot of fun as a developer. So, I thought of Nexon. It is because I have developed the games that I enjoyed the most from the user\\'s point of view. These are the games I played with my childhood, such as Illancia, the Land of the Wind, and the Mabinogi Heroics, and Nexon that developed them is a company that will make software, or games, that will continue to entertain users as it used to be. With Nexon, which has decades of development know-how and publishing skills, I thought that it was a company that I could grow with and apply. \\'Not a computer engineering student, but a developer.\\' I wanted to become a developer. However, theory classes in my second year of college were not enough to satisfy my curiosity. So, I always thought about what I could do now and actively tried to find opportunities. As a result, I was able to get two years of training from another company, challenge ACM-ICPC every winter to evaluate algorithmic performance, and a 700-member intranet management team had more than a year of experience in operation and development. Since I dreamed of becoming a developer, I have worked hard to become a developer, not a computer engineering student. As a result, I believe I have been able to design programs from my user\\'s point of view, take initiative in projects, and play my role as a responsible developer. Now I truly want to move away from being a student and grow into a developer of Nexon.\"1. Detailed analysis of asynchronous servers 2. Development of websites with dynamic design elements, rather than static ones, I am largely interested in the above two topics. First, I would like to take a closer look at asynchronous servers. Having only known about traditional synchronous servers, the way the event-based asynchronous server works has been shocking. It works like a multi-thread, while breaking down what needs to be done into pieces and processing them into one thread to solve problems with shared resources. I haven\\'t studied more deeply, but if I have a chance, it\\'s a topic I\\'d like to study. Second, I\\'d like to develop a website with dynamic design elements.I\\'ve developed promotional sites for other companies in the past, but I\\'ve used items such as parallax scrolling and responsive web partly due to limited time and resources. The project ended successfully, but I\\'m sorry that it was limited, so I\\'d like to create a dynamic site that will surprise users when I have the opportunity. And I\\'m hoping to record experiences on these issues well in the near future and do IT technology blogs, lectures, and book publications. That\\'s because I want to show my juniors that experience as I have seen your knowledge over their shoulders on the Internet or in books. It still feels like a long way off, but I\\'m preparing for that day again.\" [CasOnline] \"Because of the nature of FPS games where one person has to kill one person and one person has to kill one death, I think CasOnline has provided an interesting game mode for everyone through zombie mode. I was able to play games happily without paying much attention to the death of either human or zombie characters. So it\\'s easy to bicker with your friends when you play FPS or Daejeon games, but we had fun together with Cas Online. [Ilancia] It\\'s an RPG game that I\\'ve enjoyed for a long time with its unique elements of ability that build up skills little by little if you use it often, magic and items that give it a mysterious feeling as it is hard to get, and beautiful BGM. As it becomes Nexon\\'s classic RPG, I still maintain the same image as I did in my childhood, so I can play it with nostalgia. It was a fun game with a very simple but thrilling feeling of manipulation with the same atmosphere as a historical drama [Land of the Wind]. There is no reason, but I always remember that I chose Goguryeo and grew many different jobs. I still remember hunting squirrels as I remembered the land of the wind when I met them in the mountains. It was a game where I was so curious about how they realized it while playing [FIFA Online]. I\\'m in awe whenever I play a realistic soccer game based on discrete figures expressing the players\\' abilities and hidden statistics. If I ever join Nexon, I would like to visit the spearhead team and ask them about the structure of FIFA Online. [Mabinogi Heroics match] It was the perfect game for me, who valued manipulation. I played as a Fiona character, and the combination of sound and screen effects made the hit feel great. It was amazing how it delivered a realistic, vivid feeling while asking for relatively low points. The story line from the beginning was also exciting, so I had fun playing it.\",,,', '1'], ['[Benefit: I gained trust after finishing the organization] \"10/5/5\" is the number of part-time jobs, outside activities, and volunteer activities that I participated in. My face was always on the final photo after the 20 activities were over. I had never quit before the promised work period, and I had never let my team members suffer by dropping out under the pretext of personal circumstances in team project activities. Although the contract period is over this spring, there was a shoe store owner who called, and last winter, there was a junior who sent me a letter of gratitude for actively participating in the discussion club activities. I did my job to the end, and did not mind what others were reluctant to do. Then, I naturally gained the trust of people around me, which remained a great asset for me. \"In fact, it would be natural for a person in society to gain trust in a responsible attitude.\" However, I wanted to remind myself that the value of trust will shine greatly in the Nexon Networks game service job. It is because it is a virtue that should be equipped first due to the nature of the work that requires constant communication with customers. [Experience: A salesperson at a department store who developed \"observation\"] I worked a short-term part-time job in oral sales for 6 months at a department store. The game industry and the distribution industry are different, but there is a common denominator of customers. Beyond simply selling them, we have predicted and observed customer movement and demand for sales according to the season\\'s specialties. We have also rearranged product DP accordingly and tried to help customers as much as possible for their convenience. I am confident that this has made our customers step closer to each other. Just as we did our best in real-time sales, rather than helping them post-mortem, we will become diligent observers at Nexon Networks. ((=) We prepared in advance the demand for changes in the season through observation, and tried to increase sales through real-time understanding of customer movement. If the management team takes charge of a game as well, I think it is possible to solve the problem as soon as possible through preliminary preparation for the launch of an event or a newly released game, and quick reporting on an issue that explodes in real-time.) [Professional: Problem Analysis - Suggestion for Alternative -> A sense of number and thinking] I thought about how a public administration major would be helpful for the game service job. Due to the nature of my major, I performed tasks that required me to solve social phenomena that became issues from a neutral standpoint as much as possible. I developed an eye for even the smallest issues from a broader perspective by seeing stakeholders who have a single problem. In addition, while taking a statistics lecture, I went out to the field and surveyed the field in person, and calculated objective numbers through the SPSS program. I also acquired basic OA programs and accounting-related certificates to cultivate a sense of number,\" I learned a lot from \"3 beats for mind, communication, thoughtfulness and game service jobs.\" I encountered a lot of \"problems and requirements at each level\" that arise when dealing with people of all ages while working part-time and doing outside activities. Whenever that happened, I did my best to help them within my competence and developed a basic Mind for service jobs. In addition, while running a blog, I participated in \"ooooooo festival.ooooo oo city social media red rather than red\" and during that period, I served as a communication channel to give feedback on information and inquiries the other person needed. Lastly, I am meticulous and careful in everything. Currently, I\\'m working at an accounting firm as a part-time job in due diligence on bonds, but there are always variables and I have to approach them differently in different situations. Whenever that happens, I take notes of changes on A4 paper and come home to edit existing files by word process. In the next task, I\\'m trying to master it quickly without getting confused while watching it. I decided that I could finish my game service job at Nexon Networks with these three beats combined. [I want to represent the hearts of all users] - The primary goal is that as IT technology advances, the trend shifts from online games to mobile games, and game users\\' \\'one-time consumption tendency\\' is intensifying. It seems that the number of migratory birds is increasing and there are many people who are silent. Customers who demand complaints through email and community bulletin boards can be resolved. However, the majority of users who are below the tip of the iceberg who are turning their backs on games are even scarier. Couples who have separated from diving often do not know why, so they do not know what to fix. If I join the company in the future, I will become a versatile talent who manages expected threats along with the problems that have surfaced. [For better CRM and game system improvement] - I want to adapt to the secondary goal task to some extent and then continue to develop myself to become a professional. On Facebook, promotional activities of LG Marketing Team and Busan Police Station are being reproduced and spread with FUN elements, making them approach consumers in a friendly manner. This enhances promotional effects and brings a positive brand image. The game industry also has many activities in the IT space as its major targets are many young people in their teens and 30s. I want to study more and more \"instant\" and \"going to be swaggy\" customer care that suits them. [K-GAME Service Expert] - Third goal The final goal is to become K-GAME\\'s service expert. I remember when I was in high school, I was so into Card Rider and prepared for a competition at a PC room with the money for a reading room. At that time, I would have simply pursued joy, but now I have grown into a young man who knows the high added value of the game industry. As an IT powerhouse, I am confident that games are a leading industry that will lead the future more than any other field, and Nexon\\'s games are always leaders. In 20 years, we will grow into a specialist who can comprehensively control the service sector of K-GAME, which will lead the world, and achieve self-realization.I once served as an assistant at the Joseon Education admission briefing session. As the enthusiasm for the entrance examination was high, so was the enthusiasm of the parents. One day, a mother suddenly became angry and asked me to take out her notebooks and writing instruments that she had written down because they fell between the folding chairs in the auditorium. When I looked into why she was suddenly angry, a female employee responded that she had no choice because it was the customer\\'s mistake. An angry customer suddenly came to me and asked me to take it out, asking if I was in charge of you. Although I was a simple sub, I felt like I should take action to make my parents feel better. I tried to take it out on my stomach even though I put my hand in the middle of the chair, but it didn\\'t work. So I found the phone number of the facility management team in the auditorium hall and contacted them, and the facility manager told me that he was coming in about an hour. An hour later, the facility manager arrived and we were able to return the supplies safely through the back door opening. After that, I persuaded him by saying, \"The facility management is not under our jurisdiction, but we apologize for the inconvenience caused.\" I was able to succeed in unraveling my parents\\' feelings by showing them an effort to act in person, not just by words. [Eating with a friend from 2PM?] What help do you need to understand the other person\\'s feelings? I had a great experience to take a step closer. Last winter, I met my middle school classmate by chance at the library. While talking about this and that, I found out that I was preparing for a police officer, and I had a hard time because I went to bed three times. He said that he had eaten alone without using KakaoTalk for a year and a half, so I asked him to eat with me starting tomorrow. Then, I felt lonely and bored, but I thanked him and laughed happily. During the two-month winter vacation, we became good friends who we could always rely on while having lunch at 2 p.m., and my friend got a Kakao message saying that she would buy a meal this fall as she passed the examination only after passing the examination. Through the above two experiences, I learned to understand exactly what was required and to treat customers like family, and I want to show off at Nexon Networks.\",\" [Relieving friends\\' betrayal] - I hope only to live a conversation There is a group of five awkward friends who have been together since middle and high school. I started drinking when I was 20, and my friend A lost his mind when he drank, and my friend B was good at mischief. Usually, when we paid together, we all did 1/N, but one day, we drank a lot and B took an additional 10,000 won out of friend A\\'s wallet, saying, \"Didn\\'t you ever not?\" A few days passed after that, and suddenly, friend A left the KakaoTalk room and there was no answer. I was angry that friend C told me the whole story of the incident and he didn\\'t tell me. When I saw the act of losing money, I also didn\\'t pay much attention to it as usual without conveying the fact correctly. Eventually, B and I became dissatisfied with C, who exaggerated the incident and wanted to resolve it quickly with A, who got angry. We met in person and talked about our stories because we couldn\\'t convey a proper explanation of the situation and sincerity over the phone. It was difficult to apologize because we were so close, and it was awkward to make eye contact with each other, but I decided that it was a must-go process. A week later, everyone reconciled again, and now the conflict has not arisen because they have learned more about each other\\'s characteristics since then. The way to overcome this conflict is 1. Confronting each other 2. Conversation. Why would they not understand each other\\'s feelings again this time? If there had been no conflict, there would have been no gathering to plan a summer trip. Conflicts often arise because of the number of people who are in charge of data research without presentation while working on group assignments during school days, and at this time, they confront and talk even if they are uncomfortable for the team\\'s success. It\\'s easy to say, but I think there are many conflicts because everyone is reluctant and doesn\\'t want to do it. I want to become a humane game service manager who can hide far away and run into each other unconditionally without doing mechanical work.\"', '1'], ['I have the experience of creating a \\'similar torrent program\\' as a task for the computer network, which is an undergraduate class. The assignment was to create a \\'file transfer program\\', but the assignment was set on a relative evaluation based on the function and completeness of the program, so I decided to develop a torrent program, not a simple file transfer program. In order to develop the program, it was necessary to learn many things such as Torrent\\'s file distribution principle, understanding file processing, understanding transmission protocols, and threads. Most basically, I studied the file transfer method used by the Torrent program. Torrent divided files into equal-sized pieces, collected each piece through sharing between users, and merged the pieces back into one file. In order to use this method, we learned how to process files by dividing them into equal-sized pieces. In addition, since the program exchanges files between multiple users rather than two users, it acquired the knowledge of multiple threads to exchange files with multiple users at the same time. In addition, I learned various knowledge by creating the program, such as file transfer using Java and understanding the transport protocol. It was a tight time to acquire knowledge and develop a program within the submission deadline, but in the end, I successfully developed a similar torrent program and achieved a good grade of No. 1 on the project. \"[I have to solve the problem] I developed a chat program using the COM port for my undergraduate project. At that time, I was given a code to send packets, but if I used it as it was, the latter part of the message would not be cut off. The code was given as it was, so it didn\\'t affect the task score, but I analyzed the cause to solve this problem. The problem occurred because of the speed difference between SW and HW, and I solved the problem by delaying the transmission of messages to solve it. In the end, I was the only one to solve the problem and get a good grade called A+. As such, I will not miss any minor problems, so that no problems will arise in the future. [Not being detailed] I am not very delicate. This has led me to spend a lot of time debugging due to minor typos or grammar mistakes, and I didn\\'t read assignments carefully, so I developed the program all over again in the past. To overcome this, I have made my own habit. I set a coding method and tried to follow it. Every time I wrote a line, I checked for typos and made sure the grammar was not wrong. In the planning stage, I carefully organized what needed to be developed and tried to reduce time waste as much as possible by designing algorithms in advance. As a result, debugging time was significantly reduced, and I developed a high-quality program through meticulous program design.\"\"[Dreaming of a Happy Society with Customers] I was fascinated by the corporate mindset of Dongbu Fire & Marine Insurance and applied.\" Dongbu Fire & Marine Insurance\\'s idea that \"people come first before cars in driver\\'s insurance\" shows that it is not a company that truly values the happiness of its customers and society, but a company that can achieve happiness for its customers and society, and through this, Dongbu Fire & Marine Insurance can develop and further develop itself. As a member of Dongbu Fire & Marine Insurance, I will strive to create a happy society with my customers. [ ?   ?] I think this idiom, which everyone knows is also applied to software development. I think I need to know the nature of the program that developers develop so that I can develop a proper program. I will study everything from basic to practical for a year to understand the nature of the software that I develop. In addition, I will try to provide a stable work environment by understanding market trends and the work and characteristics of each department.\"???,,,', '1'], ['[Truthful] I always try to think in the other person\\'s situation. If you think about the other person\\'s position, you can understand the other person\\'s position. I think this helps to coordinate opinions among team members. [I don\\'t let trivial problems go by] I don\\'t let trivial problems go by. I always try to solve them with the thought that even the smallest problem can become a big obstacle someday. Thanks to this, I was the only one who solved a minor problem and won first place in an undergraduate project. [Enjoying life] I try to enjoy life and live a leisurely life. Because I think happiness is the most important value in life, I try to relax and enjoy anything, and I think I can achieve higher results because I don\\'t get stressed out.\" [User-centered software] Since I was a child, I have fixed the computers of my acquaintances, and most non-majors have felt that I am inexperienced in using them. Therefore, I want to develop software that is easy to use for anyone who is not a major. [No one knows my department] The most obvious time the existence of the IT department is when there is an IT problem. Without IT problems, no one will visit their department at the end of the day. I want to make sure that no one knows our IT department exists. [World Travel] I want to travel to all countries in the world. There are so many beautiful and wonderful places in the world that have a different look from where I live. I want to experience life once, as many places as possible, and many things as possible.\"\"I applied for a position in management planning information system to provide a stable working environment by utilizing my thorough preparation.\" I am the type to prepare thoroughly so that everything goes smoothly. Everything for the job is prepared in advance, and when you are actually working, you are thoroughly prepared to use what is prepared right away so that there are no disruptions. An information system organization is a department that provides a stable IT environment to other departments. This requires the development of stable systems and quick action and maintenance according to the changing environment. I want to use my plan and preparedness to thoroughly grasp all the environment and variables related to other departments and quickly absorb and accept the changing environment so that there is no disruption to their work. \"In a great program, stability and accuracy are important, but I think it is just as important as user convenience.\" Therefore, I think it is the duty of the information system job to provide an IT environment that is easy to handle from the user\\'s point of view. I have tried to develop a program that has an intuitive interface that is easy for anyone to use. During my undergraduate years, I developed a music playback app and chat program that focused on intuitive interface. I received feedback from users of my same type of app and reflected it in the interface development, and after all, my parents, who are not familiar with machines, are also using the app I developed themselves. In addition, we identified and reflected the customer\\'s requirements for the development of a program with functions that users want as well as an intuitive interface,\" \"[Environmentally-minded Company] We saw Descent Korea\\'s 2015 SAVE THE PENGUIN campaign in Green Plug Seoul last year. I have a habit of protecting the environment because I have emphasized environmental protection to my parents since I was young. I have my own shower sequence to save water as much as possible in the shower, and I try to save resources by using fuel efficiency as much as possible when I drive. Descent Korea, which gave up its profits and campaigned for environmental protection, was impressive. Also, I found out that the symbol mark of munchingware is penguins and that I truly think about the environment, not just in an event dimension. I want to demonstrate my ability in Descent Korea, a company that truly thinks about the environment.\",\"[From questionnaire to thesis] I don\\'t let simple questions go by. When I was in data mining class during my undergraduate days, I was questioned about the existing theory. I found that the existing similar sequence search does not take into account the size and shape of sequences, and this could lead to unintended results when there was a difference in the range between sequences. In order to solve this problem, I suggested a method of searching by reducing the difference in the range of sequence values through normalization in the preprocessing stage, and the professor recognized the validity of the idea and even wrote a graduation paper. Through this, I gained confidence to see that my ideas actually worked through verification and experimentation. I will become a talented person who constantly develops with questions, not to overlook the obvious.\",\"[International] Company Name: ***** Working period: July 2015 to September 2015 (Department): Affiliated (Department): Position of Solution Support Team: Internship Development: Premium Mall Development and Existing Premium Mall Bug Fixation and Supplementation Project: I carried out a simple Internet shopping mall construction project as an intern assignment. I used APM (Apache, PHP, MySQL) to build a shopping mall. The implementation contents included membership system (member registration, login, logout, member withdrawal, information modification), manager system (member management and product management), and DB related to products and members. As an intern, I had no web-related experience, so I couldn\\'t understand the web at all, such as how the page works between the server and the client, so I had a lot of difficulties that the big picture was not drawn in the initial planning stage of the project. I learned basic web languages such as PHP and HTML necessary for web development, and learned how the web works through online courses and books. I couldn\\'t understand the non-kinetic characteristics of PHP, so I ended up completing the project successfully through a lot of performance and error. Through this project, I came to understand how the web works, DB, and web language. [Mentoring] When I was an undergraduate, I participated in various mentoring programs as a mentor.Since I was young, I have fixed my acquaintances\\' computers and felt that many people could not use the services that computers provide properly. Therefore, I thought that it would be good for anyone who is not a non-majors to use computers easily, which led to various mentoring activities during my undergraduate years. I participated as a mentor in various programs such as mentoring younger students in the department, mentoring SCSC (non-majors software) courses, and mentoring foreign students. It was rewarding to think that more people would be able to benefit from computers if I worked as a mentor and let them know my knowledge and develop better software.\"', '1'], ['[My Life\\'s Man-Turn] I served as an Air Force communications officer, and I monitored intrusion and error of the military\\'s internal network in real time, and I always felt responsible. While serving in the military, I received news that major broadcasting companies and financial computer networks had been hit by a cyber terror attack on March 20, 2013. After hearing this news, I realized the importance of security once again, and I thought that if there was a security problem, even high-quality technologies could be useless. Through this opportunity, I made a commitment to become one of the people in charge of security in the Republic of Korea. With this commitment, I eagerly took various courses such as HW, SW, and Network while undergraduate school. Among them, the part that I was fascinated by was Network, which made it easier for us to communicate and enjoy convenient life. I studied more about Network and learned various technologies, and based on these technologies, I applied to AhnLab, which can contribute to security through control. When selecting a company that is another starting point in my life, I think about whether it is a company that can sustainably grow, rather than looking at the current situation. In this regard, AhnLab continues to strive not only for computer security, but also for the security of the latest technologies such as mobile, financial information, and IoT. I am confident that this development of technologies for new things is conclusive evidence that customer satisfaction is a top priority, not just profit-seeking. I thought we could work together toward the common goal of maximizing customer satisfaction. I will be one of the AhnLab members who will help us all live in a freer world by ensuring security in the control field I am in charge of. [AnLab which practices \\'we\\' values] I have considered my colleagues and team importantly and have a big consideration when selecting a company. I applied to AnLab because he practices the \\'we\\' values I pursue directly through a bottom-up method of collecting and discussing opinions from colleagues. When a road was disrupted by heavy rain during the long journey of bicycle land, I have the experience of safely moving to the destination by finding alternatives to meet the schedule with the members. In the summer of 2014, I went on a long journey of about 700 kilometers from Haenam to Seoul for seven nights and eight days via the national highway rather than by bicycle. During the long journey, a heavy downpour caused the road to collapse. As a result, I was unable to safely travel to the accommodations I had reserved, and all the colleagues started to tremble. I spent the day safely with some of the staff, visited the area where I could proceed with the next schedule, and fortunately, I decided to receive accommodation from a nearby cathedral on condition of cleaning up. In addition, other colleagues contacted me in advance, and even a patrol car was recruited so that I could proceed safely with the next schedule. Although I felt heavier while running around looking for a solution, I felt lighthearted because I felt that we were able to proceed without anyone getting hurt thanks to all of our efforts. I want to be a member of the AhnLab, where we, rather than one person, join forces to solve the problem.\" [Verified Human Resources Developed at AhnLab] I am the first to have the strength of being meticulous and meticulous, which is appropriate for security activities. When I was a college student, I worked on a project with Raspberry Pi in an Internet communication design class. The theme of our team was the \\'library seat system\\'. It is not just an imitation of the current library system, but a led notification function that informs users of the end time of the seat and a web seat management function have been added. At first, I thought that we could draw and synthesize the results for each part, so we performed coding work separately. When I combined the coding I was in charge of with the coding that the other team members brought, I confirmed that there were many errors because the parts were not harmonized. Perhaps due to repeated errors, all of the team members were tired. However, I completed a project as a team leader, divided the connection part of coding into n equal parts for the team\\'s good performance, and analyzed the coding in detail in the parts we were in charge of each other. We analyzed the coding we were in charge of one by one, and organized the contents of errors, so the system was able to complete the project as it worked normally. Through this project, I could feel that I had to carefully check and analyze every \\'dot\\' for IT work. The second is that I have known and done the synergy of teamwork that can maximize work efficiency. In my fourth year of undergraduate, I had the experience of disassembling the door lock with interest in the components of electronic products that I use on a daily basis, and implementing the door lock directly with my classmates to learn more about the MCU that controls the system. Unlike general door locks, the position of the number changes each time a password is entered, so it is configured to strengthen security. The number is indicated as a segment, and a touch panel is trapped on the segment, and touch input is possible. At first, I had no idea how to print numbers on the segment and how to operate the touch panel, so I had to proceed with the project by searching for information one by one. I thought it would be more efficient to divide the project rather than study everything alone at once. Through meetings with team members, each of the topics of interest were assigned, and seminars in the areas of segment afterimage output, touch panel, and circuit diagram were conducted. Through a total of 11 seminars, all team members were able to understand the flow of the project, and finally, the door lock was locked. Cooperation does not necessarily take place when you become one, but it can create synergy if you clarify your role, even if it is in a dispersed state. Finally, the third strength is completion of education and certification for servers and networks.In order to improve my understanding of servers and networks and to practice them, I studied and completed the basic Linux, Windows Server management, and CCNA Network for about six months at an ITBANK private institute. I didn\\'t stop at these training sessions, but opened my foothold as an expert by obtaining an information processor and CCNA certificate. Such strengths such as meticulousness, teamwork, professional education and certification will greatly help AnLab become a company responsible for security not only in Korea but also in the world.\"???,,,', '1'], ['[Left and right: You can do it] My motto is \\'You can do it.\\' This motto is \\'You can do it\\' when I was in second grade, and I finally got the top spot in the team project in the Digital Logic Design course, which is my first major design course, and it became more deeply rooted in my perception. The process was by no means smooth, but as a team leader, I worked hard without giving up until the end. Usually, the subject of this course was the design of digital alarm clocks, but the task we were given was the design of a hexadecimal calculator. Because the hexadecimal system is a poorly used number system, I had to organize the logic of the calculation before the design, and I couldn\\'t find any reference materials for making the calculator. I also couldn\\'t get help from my seniors, and even if I had designed it my own way, there was no way to know if it was the right design. Eventually, all of the students were hardly able to proceed with the project and had to undergo negative evaluations. When the team members started to give up one by one, I, as the team leader, felt a sense of crisis. I put off my other tasks and devoted myself to the project, devouring it into books and the Internet, putting a lot of effort into it. It was a crude design through constant repetitive learning of basic principles, but I came up with the overall idea and worked together with my team members to share parts to complete the final result. I completed the design through several sleepovers and meetings, and I submitted the final report with a nervous mind. My group\\'s project eventually won first place. After the results were announced, I was able to feel that I have taken a step further by gaining an indescribable sense of accomplishment, confidence in design, as well as a sense of responsibility, leadership, and perseverance. As a team leader, I learned how to inspire my team members, and I was able to unknowingly find myself feeling the responsibility of a leader and striving to accomplish it. Since then, I have felt that no matter how vague the situation comes, if I persevere and find a breakthrough, I can come close to success in anything.\" [Thorough Service Spirit] After the university entrance announcement, I worked part-time at a donut store for about a year. Although the location and conditions were not very good, I was trusted by the manager for a year and received the highest urgency, and I realized a lot about the professional spirit of the service industry. At the time, it was my first time looking for a part-time job, and without much thought, I ended up working at a donut store an hour away from my home. Due to the nature of my job, all the part-timers except me were women, and I worked under a kind of territoriality and criticism. At first, I had complaints and thought about quitting, but because the manager was so kind, I held back and worked hard. Since donut stores are also a kind of service business, how to treat people kindly and respond wisely to customers\\' complaints were required, but more were required when demanding customers came to complain. However, most of the part-timers were 20-year-olds in society, and they were often unable to respond kindly to customers\\' rude or unfair demands. The store manager paid a lot of attention to word of mouth because it was in the center of numerous apartment complexes, and I couldn\\'t stand by and watch. I quickly learned the task so that I could perform the role of serving customers first, and I suggested it to the part-timers. They would also be stressed when dealing with demanding customers, so if there was a problem with customer service, they would ask me to hand over the service. Since then, I have served a lot of dissatisfied customers and although I could never say it was a good time, I have received a lot of compliments from the manager for his consideration and his own principles. It is because the number of customers has increased, and the reputation of the store has been very good. It has been a rewarding experience for me because I could feel a lot about the spirit of the service industry and I have been treated well by the manager in return for his hard work.\",\"[Half Middle School Programmer] I have been exposed to computers since I was a child. Soon after, I became proficient in computers enough to take charge of computers in the house, and after gaining momentum, I bought a book when I was in middle school and challenged myself to learn the C language. Since I was a child, I liked to make things using a computer. At the time, my friends used computers to play games and listen to music, but I also used tools to make games using the mouse cursor, icons, or homepages. Then, I suddenly wondered what the source of various programs was, and while looking on the Internet, I learned about language C, which is the basis of programming. The friends around me had no idea of language C, and there was no one around me who could give me advice on language C, so I decided to teach myself recklessly. I decided to choose a recommended book on the Internet, bought a book, and started studying by following the example. However, language C did not feel easy for me as a middle school student. I was only familiar with the GUI, so I was at the level of understanding basic concepts and simple examples, such as simply outputting the results of the DOS screen even when solving examples and exercises, or it was difficult to approach the answer in principle. After finishing a book without direction, I thought about what I could do, and all I had left was \\'Hello world\\'. I felt an unknown challenge and tried to get something by scanning the book again. After all, understanding about half of the book was my limit at the time, but it later became a solid foundation for me. When I went to the electronics department, I was able to get one step ahead of others in the SW field, where everyone was struggling, and I was able to catch both HW and SW.\",\"[Flipping back] I always have a habit of flipping thoughts once in a while.It\\'s because I\\'ve frequently experienced unexpected and far better directions. For example, when I was working on a team project in a digital integrated circuit subject, I scored high in a different way than others. I was usually interested in this field, so I completed the team project much earlier than the deadline. When I finished the result report, the team members were no longer interested, but I thought, \"What if it\\'s not completed as usual?\" Meanwhile, I discovered that my team\\'s and other team\\'s topics could converge. Our team\\'s topic was to output RGB data received through the camera module, and among the other team\\'s topics, to adjust the pixel data through coding and display a picture on the monitor. By combining these two, we came up with the idea of connecting RGB data to the input of VGA Control and outputting the image from the camera to the monitor. As the team had already completed the project, I proposed a collaboration, and the two teams combined the topics to work on a new additional project. Although the difficulty of both topics was so difficult that we were unable to complete the original project due to time and technical constraints, we succeeded in printing out RGB data in color on our monitors. After our team\\'s presentation on the day of the assignment, we announced about additional projects. Because we were the only team that worked on additional projects, not only the students but also the professors were surprised. After the presentation was over, the professor said this is a case in point. In the end, both teams received the highest marks in the project section and completed the course with high grades. This was the most gratifying and meaningful thing that I have achieved by the habit of reversing thoughts in the opinion of the majority.\"\"[Almighty engineer on the principle of communication and consideration] My most important values are communication and consideration, and my dream is to be an omnipotent engineer who can do anything well. I have always worked hard to achieve these two goals, not only in my studies but also in my life. In order to experience the corporate culture that I have not experienced in person, I have experienced a sense of belonging by working on card inspection and documentation for about a month in the R&D team of Korea Smart Card. I mainly performed frequency and non-destructive inspection and documentation work. In addition, during vacation, I learned how to use the tool and basic knowledge by receiving PCB design training using Cadence\\'s tools. I have tried to develop both hardware and software skills. Through various classes in the curriculum, I have developed my ability to handle MCUs skillfully, not only understand simple codes but also code to code programs, but also learn the roles of each MCU pin or how to use communication functions when necessary to enable various types of application coding. Using this, I also created a graduation work under the theme of \\'Home Automation Using Zigbee Communication\\'. Within the team, I was in charge of designing the overall structure of the work, building a wireless communication network, coding, and circuit design of a control unit. In addition, I was passionate in related subjects and received high grades based on understanding, not memorization. My top priority is consideration and communication. I have always thought that the basis of a smooth human relationship comes from consideration and communication, and I believe that it has a positive effect on everything. Based on these, I would like to contribute a lot to the path to becoming an SK C&C that is second to none in the world by becoming an engineer who promotes innovation and leap forward without falling behind the technological changes that are developing day by day. I am also confident that I will develop a sense of affinity and cooperation to lead a smooth company life, improve efficiency, and work with a mindset appropriate for new employees.\",,,,', '1'], [\"The most difficult question is, but I think I am an evaluator of the National Insurance Review. When it comes to caring for the people and improving the health of the people, I think thinking about others is the priority over me. I don't think I'll know if I'm fit or not if I work. Please print it out for me. I'll do my best. I have little competence, but I don't think what I can do is small. When the existing method becomes complicated or has a lot of work, I use software convenience to provide a simple and quick response method or coordinate opinions with the engineer and the required part. There were parts that were usually not accepted, but in the end, they accepted the opinion that we should develop it in an easy direction. My work was not remarkable because it was a project with several programmers and companies, but I was happy and rewarding when the work was completed well. I performed the work with the help of colleagues, related data from A, or the advice of related engineers. I coordinated or coordinated the differences in opinions or interests between developers, engineers, and A while carrying out the business of the company. Since there are numerous engineers at each stage, meetings are frequent, and the outcome is important in the final stage, so I express my opinion in advance on sensitive issues. I respect the other person's opinion because most of the work is subordinate to the system that listens to others' opinions, and if I have a new idea, I will express my opinion, so if a new idea is outstanding or a new item, it will be adopted. I also tried to collect the opinions of seniors and colleagues in areas that I did not know at all. So, I received a lot of help from my colleagues and received advice from my boss. If I thought it was unfair, I also offered a different opinion. I tend to talk about things in advance about how to do this, how should I do this, and it seems that there were many things that the senior should consider because it's a newbie's burdensome part because it's a job with a senior like this. He was a grateful senior.\", '0'], [\"I have come to realize that even a small change in things can be revolutionized, not just by developing and inventing things that go against the times. I have come to pay attention to the fact that small changes can distract and lead many people. Data analysis can help us understand the current public's interest, and we must manage it effectively to increase the value of our data. At a time when the importance of data is increasing, I will perform my duties with the responsibility that I contribute to the health, convenience, and stability of society, rather than collecting and managing a large amount of data meaninglessly. With this mindset, I will work passionately with the goal of protecting the welfare and health of the public at the Public Officials Pension Service, where vast amounts of public data gather. It will be efficient and planned for the status of the public corporation and the welfare of the public, and I will not lose my generous attitude such as maintaining security and managing robust networks as it is a place where a lot of data is gathered. I have experience in carrying out projects with the aim of using IOT smart farm equipment in Capstone design. With the help of many data search and acquaintances, I was able to produce frames using profiles and motors, and I controlled the sensors using Raspberry Pi and Arduino. The value for this was based on mysql, and the data was managed by establishing a database. Through trial and error, I learned that we must not lose our will, such as server construction, computer, Raspberry Pi, and mobile connection, and voice recognition technology that we did not expect when applying the first-time voice recognition technology. I think that the management of the public corporation's database is important in order to proceed with the work for pension and welfare. During the project, we will make sure that the work proceeds smoothly with the attitude and mindset of responding to errors. I think the information system is the most appropriate content among the contents I have been educated. The goal of this lecture was to learn the theory of basic network systems, databases, and management information systems. Introducing computer systems mainly for companies, I took practical environments and technology application cases during the training. Since I work to manage pensions and welfare, I think I need a lot of accounting and management knowledge even for computer workers. When I looked for the actual work arrangement, it was similar to what I expected. Economic knowledge is also essential to build and manage databases because it is a computer job that is deeply related to other tasks. When all these points were combined, I selected an information system among the training I received.\", '0'], ['It is a game derived from the world view of \"Haston\" World of Warcraft and is in the form of CCG. Unlike conventional card games, each card pack has a season expiration date, which enhances business continuously and provides users with a variety of gameplay. In particular, it has overcome the disadvantages of high satisfaction and boredom because it provides exotic attitudes such as \"speculation\" and \"tap shop struggle\". In addition, since both PC and mobile can play the game with the same interface, anyone can access it easily and quickly because there are no space and time constraints. \"Competition\" He was an ordinary child with nothing special since childhood. That\\'s why I had a high sense of competition for my friends around me. I had a desire to do something that much when someone did something. The first start is competition for a cousin of a one-year-old boy, who turned 10 years old. When I listened to the sound of a prodigy by memorizing a thousand letters, I thought I could do it, so I started learning Chinese characters. While learning for the next four years, I felt a sense of accomplishment through the Chinese character test, and as a result, I received excellent grades in Chinese characters in middle and high school. During my school days, I started memorizing world maps as I competed with a friend who memorizes world geography, and I appeared in the Golden Bell as a specialty. Once again, when my friend\\'s writing skills improved, I started reading essay writing and won an essay contest for the first time in my life. In the past and now, I am an ordinary person. However, I am full of aspirations to improve. In the future, I will continue to digest the strengths of people around me with my own and develop myself. There are many really important moments when playing games. The moment you beat Boss Monster in Reid, just before the game was decided, and you pushed your opponent with a trickery of your own accord... What if the game server explodes or a bug breaks out at this time? Just imagining it is terrible. Game QA plays a role in preventing the gamer\\'s love for the game from cooling down by checking servers and systems countless times to prevent such a situation from occurring. To perform this role, stable server and system operation skills are required. After graduation, universities dealt with various server OSs, took information security-related lectures in vocational education, and improved equipment management and vulnerability inspection skills. I will become a game QA that responds quickly to any obstacles.', '0'], ['\"When I Like And Enjoy, Sometimes I\\'m Annoyed and Angry\" I think this is passionate to do something consistently that makes you like and enjoy it, and to have a combination of annoying and angry feelings. If you like something and enjoy it, someday you will get annoyed. It is because you run into limits, fail, or get frustrated. The will and effort to overcome these hardships is the definition of passion in my opinion. When I was in the second grade of middle school, I first learned how to play basketball from a friend. Friends who I first learned like me improved just by exercising together on a regular basis without much effort. But it was different for me. I was always halfway and behind. I didn\\'t get the spotlight, and I was something I didn\\'t need or needed. I was angry because I liked basketball more than anyone else and enjoyed it. So I practiced. I went to the basketball court in my apartment at 10 p.m. every evening and fried and threw it by myself. After more than six months of hard work, I reached a position where I could participate as the main player of the competition, and was recognized by my friends as well as skills that I am only good at. This experience has given me a sense of value that there is nothing I can\\'t do if I have passion. I believe that anyone can do it no matter what the difficulties are. I had the experience of challenging programming with confidence while taking the \\'Web Programming\\' course. At that time, I was not good at programming. I envied people who were much better than me, but I had a ambition that if I tried, there would be nothing I couldn\\'t do. I personally learned by using books and internet lectures, and I carried out small projects and practiced at the same time. After hard work, I was able to proudly receive an A+, and that effort instilled my goal to become a Back-End developer. After achieving that goal, I have steadily studied on my own and have proudly passed the internship and development club. Although each failed once, I was able to achieve it by challenging with passion and confidence. After joining the company, you will face more adversity than you do now. However, I will become a developer of SoftSen who always grows with the confidence that there is nothing I can\\'t do if I try hard and the passion I defined by myself as I have done so far. If the goal of \\'growth and contribution through co-prosperity\\' is the same, I think I can contribute to the company actively as well as voluntary individual growth. I have a goal to become a Back-End developer. Furthermore, I want to build a career by moving on to the cloud and big data fields. In this respect, SoftSen decided that my goal was the same as mine. Currently, SoftSen provides web solutions based on cloud and big data. Therefore, I have confidence that I can grow quickly through leading learning because my goal and SoftSen\\'s service are the same. For example, I have experienced voluntary efforts to build up the back-end development skills that I aimed for. I tried to improve my development skills by continuously refactoring my personal projects. Mainly, we perform refactoring in terms of improving code or applying newly learned technologies in an object-oriented manner. For example, I have experience repactoring the \\'department bulletin board notification\\' in the order of Socket, JSP, Spring, ORM, RESTful API, module separation, and AWS. As such, I have tried to improve my development skills by applying various skills and knowledge learned through this experience to my actual code. Therefore, if the job goals are consistent, I think that of course, leading learning can lead to corporate performance naturally. Even after joining the company, I will not only simply organize the knowledge I learn, but I will also continue to grow as an S/W developer who can contribute to Softscene by improving my development skills by applying it to individual projects. In order to solve the problem of \\'new article discrimination algorithm implemented with string\\', I constantly asked the question, \"Is there any other way to compensate for the exception?\" At first, I thought that there was no other way than what I implemented now. However, in order to break away from the existing thoughts, I constantly asked myself questions and suddenly popped up on the way home and was able to solve them. It would be nice if I could make it perfectly from the beginning, but most of them think that I have to go through \\'refactoring\\'. Through this experience, I realized that continuous worries can provide clues to solving problems. I will always be responsible for my work and be reborn as a talented person who can solve problems through constant worries. #Problem \\'How to determine new articles\\' There were two ways I thought of determining new articles. First, comparing the number of posts in Nth crawling with the number of posts in N+1th crawling. However, this method was unable to distinguish new posts because the number of posts would remain unchanged if the posts were deleted and added once between Nth and N+!th crawling. Second, comparing the number of posts and comparing URIs in the top posts. First, as a supplement to the method, even if the number of posts remains unchanged, if the URIs in the top posts are different, it is determined that a new post has been posted. In this case, similarly, if deletion and addition occur once within the crawling cycle, the URI values were the same because the posts have the same index, so we could not discriminate new posts. Comparing the titles of the top posts was an additional method, but we thought that this was not a fundamental solution because there was an exception that the title might be the same as the previous post in this case, and the code would get messy due to many variables. #Resolution We fixed the issue by using HashMap, Java\\'s Collection. KEY of Map saved the URI of the post, VALUE saved the title of the post. The reason we used Map is that the URI of the post is guaranteed to be unique. Since the post request API usually uses the GET method, we focused on the feature that each post has a different query.As a result, we were able to identify a new article by finding the existing KEY, that is, the URI of the post, using the contentskey method between the existing data and the newly crawled data. We will fully understand the back-end that is the basis of the solution. Until now, we have been developing the back-end using Java and Spring Framework in private projects, interns, and development clubs. Therefore, I am confident that I can learn faster and fully utilize the Java web technology used in practice by bumping into each other. My weakness is that I have no experience related to big data and artificial intelligence. In order to turn my weaknesses into strengths, I will read the book \\'Big Data Technology Learning as a Working Project\\' to get a sense of big data. After that, I will identify the big data-related technology stack used by SoftSEN and proceed with the personal project using the technology. AI will learn basic knowledge from deep learning to machine learning and proceed with projects that imitate the most basic AI programs. Through this, I will grow as a developer who can build up big data and artificial intelligence capabilities and develop core technologies. If it is clear what to do, no matter what difficulties there are in the process, it is my personality and strength to achieve them. For example, after setting a goal of becoming a Back-End developer, I experienced the adversity of being rejected by interns and development clubs in order to develop my Back-End skills. In order to overcome the hardships, I learned theories through books and internet lectures and proceeded with personal projects, developed my skills, and I was able to re-challenge and pass the examination with confidence. After joining the company, there are certainly many things I do not know, and I may be given assignments that are beyond the current level. However, I will become a developer who grows by achieving my goals for big data and artificial intelligence with the same challenging attitude as now.', '0'], ['\"The Best Value Partner\" There are three reasons why I applied for the Modern Information Technology. First, the vision of modern information technology to open a more convenient world with advanced technological skills and know-how is consistent with my vision. Second, it is the growth potential of modern information technology that supports domestic and international businesses with IT, such as the establishment of a next-generation system in the Vietnamese stock market and the establishment of an ATP signal system on the ground. Third, the human resources that modern information technology pursues are consistent with my values, which I am not afraid of failure and constantly strive for. To become a member of modern information technology, I took an applied SW engineer training course at OO Information Education Center, acquired various IT knowledge such as Java, JQuery, Oracle, and MyBatis, and gained practical experience by conducting projects to develop \\'Free Video Lecture Site\\' and \\'Secondhand Auction Site\\'. I will contribute to establishing modern information technology as The Best Value Partner by developing solutions that succeed L-Cloud based on my capabilities and core values of 5C. \"Collaboration, Growth DNA\" My growth DNA is \\'collaboration\\'. When I was an undergraduate, I learned the power of collaboration by working on several team projects, and I have grown into a person who practices collaboration. For example, I have experience in collaborating in the \\'In-school Course Registration System Improvement\\' project and obtaining results from the 7th to the 2nd in the final evaluation. The final goal of the project was to express the functions delivered by the improved system in UML such as use case, ERD, and DFD. To make matters worse, there was a team member who was left behind in a situation where a small number of people had to bear a large amount of work because the team member who was in charge of PM was excluded on the way due to early employment. Since I was a double major student, I was a team member who lacked basic knowledge of UML. I delivered reference materials, helped Q&A, and filled out the deficiencies of my team members. At first, it was somewhat difficult to learn unfamiliar concepts such as objects and attributes, but as a result of steadily helping me learn, I wrote DFD without difficulty. The task I was very overwhelming. However, when I first learned UML, I tried to understand the situation of the team member by recalling the old me, which was difficult, and I tried my best to recall that it was a common goal. This led everyone to participation without a single dropout. I think collaboration not only means that everyone works together to cooperate, but also that if there are colleagues who are struggling, they are willing to self-impose themselves and share and lead the difficulties. I will be a co-worker of modern information technology that creates team results by demonstrating my ability to collaborate, which is my main weapon in the IT industry, where collaboration is the main task. \"First Social Experience, OO Research\" The most memorable experience I had with interest and enthusiasm other than my studies was the OO research internship. It was my first social experience, so everything was unfamiliar and difficult, but through this experience, I learned the basic competencies necessary for working at a company, so it was the most memorable experience. My task was to develop an online survey page and manage the survey DB. While reviewing the survey DB conducted on the subject of \\'children\\'s education level according to whether parents are economically active or not\\', I found that the survey of respondents on parental leave was incorrectly classified as the economically active population. It occurred because the interviewer did not receive the purpose of the survey accurately, and we had to conduct an additional survey with little time left until the deadline. If smooth communication had taken place from the beginning, there would have been no such mistake. Since then, in order to minimize communication confusion, my intention has become to accurately communicate with the other party and to immediately take notes on what I have received. In addition, during my six-month internship, I learned an attitude that is trivial but should never be overlooked. For example, when I was handed a task, I realized that it was more important to ask questions immediately and accurately acquire the instructions and give them prompt and correct results, rather than try to reverse the task by myself if there was a blockage. I will show my communication skills, ability to perform tasks efficiently, and practical IT skills gained through experience in Korean research internship in modern information technology to the fullest. In this way, I will become a new employee who is good at modern information technology and wants to work with. \"Transfer convenience through creativity\" My strength is to make people\\'s lives more convenient by adding creativity to the skills I gained through various projects. For example, I proposed a virtual manager account by demonstrating creativity in the \"Second-hand auction site development\" project. The goal of the project was to develop a used auction site where safe transactions are guaranteed by supplementing the limitations of used sites where disagreements arise during the pricing process, and where people can purchase the desired item at the desired price. I was in charge of linking membership DB such as membership registration, login, information modification, and withdrawal. For the safety transaction, which is the main focus of the development, I proposed a \\'manager virtual account\\', a system in which the manager first manages the amount deposited by the buyer and then transfers the money to the seller after the buyer receives the item, to emphasize the difference from the existing used sites. As a result, it won first place in the creativity and convenience category among a total of eight teams. I think creativity is an essential element for developing technology that keeps up with the rapidly changing IT era. We are ready to support modern information technology that focuses on expanding cloud services and BI businesses through IT services based on creative thinking. \"Overcoming the \\'urgent personality\\' by helping me,\" There are times when people around me feel burdened by my urgent personality. At the time of the project, I felt nervous as there were signs of being a little later than the schedule, and put an unexpected burden on my team members. Rather than just watching and getting nervous, I decided to help my team members after finishing my task quickly. \"Fourth Industrial Revolution, Cloud\" With the advent of the fourth industrial revolution, the IT trend that is emerging right now is \"cloud.\"The cloud is at the core of the 4th Industrial Revolution, so it is called the cloud-based data revolution. Hyundai information technology is responding quickly to the 4th Industrial Revolution by providing integrated business solutions through the signing of MSP partnerships with Oracle Korea. My goal for the 10 years after joining the company is to participate in the response of modern information technology by developing cloud solutions that succeed L-Cloud. With this, I want to lay the foundation for Hyundai information technology to grow into a leader in the 4th Industrial Revolution. During my undergraduate years, I was working on the \\'Smart Factory Design Plan Using Cloud Computing\\' project and discovered the limitations of SMEs that were unable to introduce smart factories due to lack of professional manpower and financing problems, and came up with an improvement plan using the cloud. I want to share the heart-rending work of actually building the designed system with modern information technology.', '0'], [\"This was when I participated in the Campus Patent Strategy Universiade. First, in order to understand the technology of the patent related to the technical equipment in question, the main components of the patent were analyzed and understood the technology. Then, based on the analysis, related patents and papers were found. I searched for the main components as keywords and found the core literature related to this patent. However, I looked for patent infringement products in Korea, but I couldn't find them, so I even reviewed the data sheets on the products of representative companies in the United States related to patents and found a product that is likely to infringe on this patent. And, judging that there is a possibility that this patent may be invalidated through the preceding literature, an avoidance design was suggested. As a result, I was able to obtain good results from the CEO award. I will become a new employee who is assigned to the IT department of Hanwha S&C in the position that I have achieved by challenging new things and eventually achieving them with my own attitude. Over the past six months, I have gained expertise and practical experience by participating in the on-campus 'Big Data Manager Course' conducted by the IT OOOO Association. I learned JAVA, JSP, Oracle, Hadoop, and R. I worked on a total of four projects on various topics and learned teamwork through communication. After that, I participated in the 'DA Design Contest' and modeled the data on the human resources management system of a company. While modeling data that meets the requirements of the company, I learned the practical skills of B2B, which are different from those of B2C. Based on this, I will become an essential human resource for sustainable growth as an IT leader. It was time to design an information search system as a graduation project. In the first evaluation among the progressive teams, our team, which was at the bottom of the evaluation in all areas, overcame difficulties and won the first place over all teams in the last final evaluation. We developed a system that enables users to search efficiently through pre-construction of technology classification and expansion of quality. I learned teamwork in the process of solving problems based on collaboration such as system design by taking each part. When I was in college, I was the team leader when I was working on a coffee vending machine design project. When I was working on this project, I tried to proceed with it by collecting everyone's opinions like a sponge. However, when I decided on the direction of progress including all opinions, the progress of the work was slowed down, so I couldn't complete the target design properly. In order to overcome this shortcoming, we will maintain the method of collecting opinions, but use a quick solution in reaching a consensus. The keyword of the IT industry is a challenge called 'CREATIVE' through the convergence of new technologies and existing fields. In addition, it is changing into an era of 'SMART' system and service that provides heat by adding one. With an interest in big data that will be considered more important in the future than today, I have developed related capabilities through the six-month 'Big Data Manager Course Training'. In addition, I designed an information retrieval system as a graduation project. The system was developed by the user through the algorithm through the pre-construction of the technology classification, the two-stage query expansion, similarity comparison, and text rank algorithm. This gave rise to the competence of SMART and CREATIVE. Companies are fiercely competing to take the lead in the market of the IoT, which is now and just around the corner. The IoT, which will be an important technology for the IT market and the overall industry, will be the goose that will produce a golden egg to create numerous values such as smart home services, self-driving cars, smart factories, etc. Hanwha S&C is striving to become a leader in the IoT market through an intelligent management system, a smart exhibition hall at COEX, etc. However, in order to lead the IoT market, Hanwha S&C needs to build its own infrastructure. I think that if we build our own infrastructure in preparation for the problems of the data surge that will come due to IoT problems in the future, we will be able to take a step ahead of other companies. To overcome this problem, there are ways to build infrastructure based on cloud computing, efficient storage, and big data analysis. It will be important for Hanwha S&C to take advantage of these factors in advance.\", '0'], ['* Common and detailed technical requirements Software architecture / Software engineering / Acquire judgment to accurately accommodate and reflect user requirements Software architecture / System analysis and design / System components to clearly distinguish them and learn how to deliver network packets through basic network education and programming learning Application software / Mobile network programming / Application software using Android and network communication Application software / Linux system programming / System application software using Linux operating system / Object-oriented Windows programming / Programming instruction using MFC Application software / C programming instruction database / Database basic theory instruction database / DBMS utilization and practice / Small-scale projects using DBMS / Computer network / Network and data communication / Basic theory education on how to communicate between network and data / Computer security / Cryptology entrance / Com / Computer language using MFCIntegrated Security Basic Education for Computer Security / Internet Security / Network Analysis (English only) / Making proposals through analysis and planning of vehicle-related communication networks among current communication networks / Information system specialization / Application software suitable for Korea / OOO Academy Program / Java, Android, HTML5, Team Project and Interpersonal skills / OOO Cooperative / Oracle Database 12c / Oracle University Software Architecture / ITIL v3 Foundation for Software Engineering and Certification Process / ITSM Course / ITIL Education Center Software Architecture / ITIL V3 Foundation for Software Engineering / ITIL V3 Basic Curriculum based on ITIL V3 / Basic Curriculum based on ITIL V3 / Java Programming / OO Education Center Software Architecture / IEEE Principles of Software / IEEE-based Software Engineering Education / OO Campus Online Education Software Engineering Education / OO Campus Software Engineering Education Architecture / CMMI-DEV for IT Development / Development Methodology for Efficient IT Development / OO Campus Online Education Database / SQL Tuning to Increase Query Usage / OO Campus Online Education - C: Network Programming, SMTP, QualityNet/Skilled (Medium) - JAVA: Book Management Program, Safety Service Application/Skilled (Medium) - Python: Machine Learning/Skilled (secondary) - Project Management Application using Python Library (ERP, MES, Location-based Service, App Card) - Reason: The service that can be most helpful for OO Card and the Java Object World you are aiming for - Latest Mobile Service: Games and Shopping - Reason: Since men mainly use games and women use mobile commerce services, games and mobile commerce services for those in their 20s and 30s, which are the address class, are perfect for providing pleasure and moderate stress by providing services to all humans. [Company Project Experience] 1. Project topic related to company career: OO Fire & Marine Insurance ITSM Operation and Advancement - Period: September 2015 to January 2017 - Personnel: 3 Development personnel, 4 Planning personnel - Affiliated (Department): OO Fire & Marine Insurance IT Support Team > Customer Support Unit > Quality Management Team - Position: Employee - Duties in charge and performance project: IT quality management through ITSM operation and advancement, KPI adjustment work in year/month of Fire & Marine Insurance Center - Importance of duties and performance project in charge of company: Employee level (ITSM Enquiry Response and Solution Implementation Work Response, Maintenance Management and Integrated Management Ledger Management - Web Enquiry Response and Improvement) - My role (especially when the project is in progress): Can modify KPI of the entire Fire Management Center, increased convenience of implementation using the solution - Performance and achievement: IT quality management through KPI operation and development in year/month of Fire Management Center - Possible scope of work: Development, operation, planning, IT-related documentation preparation, quality understanding, security [ Graduate project experience (Laboratory of ubiquitous networking at OO University)] 1. Project name: Evaluation of wireless communication and application services for cooperative vehicle safety system.Roles of building certified infrastructure: Project researchers: 3 people in charge: Research and development of radio wave models for V2X (development of source codes for radio wave models in C programming-network simulators), research on trends related to radio wave models using simulations and papers: 2013.11.01 ~ 2014.08.31 Agreement Agency: OOO Parts Research Institute 2. Project Name: Establishment of SW platform for ICT equipment: Project researchers: 5 people in charge: Planning and drafting proposals for the first year of the project (motivation of proposals, points to be revised in the future) Period: 2014.05.01 ~ 2015.04.30 Agreement Agency: OOOO Industry Promotion Agency (Daejeon Office) 3. Project Name: V2X Core Technology Research Role for WAVE-based vehicle cluster control and communication: Project Number of researchers: 10 Person in charge: Project proposal revision and additional trend survey Period: 2013.09.01 ~ 2014.08.31 Agreement Agency: Project Name: OO Research Foundation 4. Role of development of real-time emulation testbed for V2X safety service: Project number: 10 Person in charge: JAVA Programming (Safety Service Application Development - Application for network simulator) Location and mobility information of vehiclesUI on location) Period: 2013.05.01 to 2014.04.30 Agreed Agency: OOOO Industry Promotion Agency (Daejeon Office) [University undergraduate project experience] 1.1st grade - role (personal development), in charge (C language: using basic algorithms such as triangle, rock-paper-scissors, diamond, etc.) - role (follower), in charge (college student programming competition problem solving, 4 out of 10 questions) 2. 2nd grade - role (two-person team leader), in charge (Java: Book management application development) 3. 3rd grade - role (four-person team leader), in charge (JDBC bank management system UML work and development general management) - role (three-person team leader), in charge (MFC poop avoidance development, Windows programming study operation, project presentation PPT writing) - role (four-person team follower), in charge (four-person team follower), in charge (network programming-ubuntu, development of SMTP using C language, modification of source code for client function, presentation PPT general) 4. 4th grade - role (four-person team follower), in charge (Android calendar memo app development, app user information management function, and overall UI function development) - role (individual development), in charge (implementation of OS Roundrobin algorithm) - role (four-person team leader), in charge (graduation thesis: grafting OTP onto FTP (java development - utilization of open source), OTP related trend survey and app development, FTP application implementation) - role (three-person team leader), in charge (college student pro leader), in charge (university student pro leader)Graming competition problem solving, C language, 3 out of 10 questions)', '0'], ['I think the project \"PM specializing in risk management of production management\" started with business innovation. In order to generate profits for Samsung Electronics, I became the current Samsung Electronics by identifying, educating, and growing the merits of talented people. I want to be a risk management PM. I gained social experience in various fields by working in a lab for 7 years at a university and graduate school, and part-timer at a coffee shop and head hunting company for 4 years. While encountering IT technology from college to now, I think that the role I want to play and what I am good at are the role of ICT PM of Samsung Electronics. Although I lacked knowledge, I was able to expand my major competency in algorithms through the Internet and major books, and I was able to expand my knowledge deeply and broadly by visiting the professor and showing the design of the algorithm I think. These efforts enabled me to gain a holistic view of the IT industry, and I acquired knowledge of the entire computer by drawing CPU design by hand in the computer structure. When I was a graduate student, I was able to realize the practicality of knowledge by specializing in vehicle communication networks, and I gained additional capabilities in algorithm modeling as I proceeded with the business. I will try to become a PM for Samsung Electronics what I learned through YouTube, books, libraries, colleagues, seniors and juniors. I will become a PM specializing in risk management at Samsung Electronics in the future. Bruce Ekel, the author of Thinking in Java, a Java book called \"Extreme Development beyond 20X Productivity,\" said that the difference in productivity is more than 20 times depending on whether the algorithm is used properly. I am continuously making efforts to equip myself with the capabilities tailored to the convergence of hardware and software in order to create higher productivity through cooperation with Samsung Electronics in addition to synergy with technology workers. Based on the experience of programming in the Linux development environment since college, I have continuously gained experience between hardware and software by displaying pictures on embedded equipment in the Linux environment in the graduate school. I have taken actions to solve algorithmic competition problems since I was a college student and laid the foundation for my computer knowledge through differential calculus and engineering certification for the continuous development of the computer field, which is the basis of my capabilities. In order to continuously modify and improve simulations, the graduate school is making efforts not to miss the details while studying algorithmic problem-solving strategy books, and has the ability to draw an algorithmic blueprint using a modeling language on background paper. I have worked part-time at coffee shops, headhunting companies, and family restaurants for four years since I was an adult, and I have realized the importance of conversations with people in various fields and the need for consideration. At universities and graduate schools, I was able to be reborn as caring seniors and juniors among my friends, and I was able to give positive motivation to everyone by saying that whenever I was working on a team project, I was always possible. A mockup is a life-sized model that is made for product testing. I consider myself a mockup for the development of Samsung Electronics. Just as the graduate school\\'s goal was to produce the most suitable and perfect simulation results by continuously modifying simulation experiments repeatedly, I tried to become a talented person who can be used practically for Samsung Electronics. As a human OOO, not a student in the Department of Computer Engineering, I visited Samsung Delight Shop as if I were having a meal as I was interested in laptops and tablets among electronic devices. Recently, as I became more interested in ultra-books, I watched videos of disassembling and assembling mechanical parts directly from YouTube, and bought an SSD myself, and made it fun to assemble it to a netbook at home, and test its performance. Samsung Electronics\\' unique technology instills great passion and dreams not only in terms of technology but also in the younger generation by creating smartphones, smart TVs, and Tizen operating systems that Samsung Electronics actually releases. In addition, I think Samsung Electronics is lighting up all classes of society by personally practicing continuous social activities through cooperation with Samsung Electronics\\' volunteer team and volunteers from the Korean Red Cross. As a Samsung Electronics person, I want to show dreams to someone through technology and reveal all aspects of society, so I want to be a mockup of Samsung Electronics. \"Is it connected right?\" I believe that connection is the core of the biggest social issue. The biggest example is the Fourth Industrial Revolution in the industry. Starting with smartphones, new terms such as ICT, big data, and connected cars poured out in the IT world, and as a result, large corporations began to expand their roles, SMEs began to expand their work, and new venture companies began to grow indiscriminately. However, while these growths and revolutions seem to be going in the good direction in the world, it is true that there are no real results in Korea. Take the Internet, which was considered the best in the world. Korea is the fastest. However, for the 5G that is emerging today, legislation and clear standards have not yet been properly designated, so it is common to follow international standards. Of course, it seems that there will be new winds and hopes in the industrial world due to measures such as creating its own OS like Samsung, but it is true that it is technically and practically lacking. What we need to look into here is the importance of connection. It is necessary to properly investigate the actual condition of the technologies centered on the connection that Korea currently has. I think that the cooperation of companies is becoming the most important accordingly. Large corporations accept new technologies when acquiring venture companies, but they must carefully investigate and properly acquire new technologies. Mid-sized companies and SMEs should focus their management capabilities on IT and focus on fostering new human resources. Of course, these aspects are essential requirements for a company, regardless of the size of the company.In addition, I believe that Samsung Electronics should be a first mover or a leader in new technologies through connection. Samsung Electronics should develop the driving force that can lead the Nth Industrial Revolution beyond Korea\\'s 4th industry. Future convergence talents will be needed, and I will connect them through production management.', '0'], ['\"Success and Failure Through Challenges\" I am either oversensitive or overly cautious, and I am careful when speaking. To compensate for my shortcomings, I always act passionately with new goals. I have a habit of taking notes while carrying a ballpoint pen and notebook to check myself. When I was in college, I was curious as I participated in a college programming competition, and I developed logical sensitivity and passionate behavior. When I was in graduate school, I created ideas with researchers while exploring academic papers and overseas journals for new ideas related to vehicle communication while writing proposals, and I was able to contribute to ideas related to simulation and modeling. As a Korean fiS, I will contribute to the research and development of information technology that can create new and certain profits in the Nth industry through passionate brain activities and careful decisions. When I was a freshman in college, I took an engineering certification course and acquired basic design and development capabilities to become a talented person in Korean fiS. I acquired basic knowledge such as physics and mathematics for efficient software design, and I wanted to design and drive the device myself with the team while taking design courses such as engineering design and system analysis and design, and I wanted to get opportunities for design jobs while improving existing design methods. I tried to find a point of contact through the pleasure of communicating with the other person, interest in new information technology, and the convergence of my computer engineering knowledge, and I gradually embodied these ideas to target my business with the goal of convergent IT WooriFISIN. Through cooperation learned in team project design and acquisition of algorithmic knowledge in engineering certification, I developed the engineering design competency cultivated to me. I have three actions. The first was to read more books and learn all the time because I still have a lot of things to lack. The second was that I should be interested in developing systems as a computer engineering student. Finally, I had some free time to read good humanities books, or researched the latest technologies in person during network time. \"Target-tailored development for perfect systems.\" An impressive example of my recognition is the graduate school experience. In the second semester of graduate school, I developed a safety service application for accurate vehicle communication simulation using Java programming. The safety service application that I developed was able to expand the research as it was used as a cornerstone of an application for safety services that was actively studied both at home and abroad in the vehicle communication laboratory where I graduated. Recently, the importance of building and operating customized systems for consumers is increasing. So, as a member of the FIES, I investigated the trends in the existing FIES infrastructure for the use of information technology safely and efficiently, and I think that what I can do to solve the inconvenience of the FIES people is to supplement the system through the knowledge of computer structure. Until now, I have studied computer structure and Internet security and am making efforts to consider the safety and efficiency of the system. In addition, among the experiences I had with a new colleague, I had worked on an Android development project. I applied for the FIES because I think my capabilities will be the most necessary foundation for our performance as the number one researcher that customers love. Bruce Ekel, the author of Thinking in Java, among the \"Extreme Development beyond Productivity\" Java books, said that the difference in productivity varies more than 20 times depending on whether the algorithm is used properly. I am continuously making efforts to equip myself with the capabilities tailored to the convergence of hardware and software in order to create higher productivity through cooperation with the FSIS as well as synergy with us. Based on my experience in programming in the Linux development environment since college, I have continuously gained experience between hardware and software by posting pictures on embedded equipment in the Linux environment in the graduate school. \"There is no impossibility of endless effort.\" My efforts include the ability to become a simple, overcoming talent. In college, I completed software-related algorithms, programming, object orientation, and computer structure, and additionally completed basic mathematics and physics for the efficiency of algorithms. Through my major in system analysis design, I have developed the ability to design big pictures of software using software programs. Although I lacked knowledge at first, I was able to expand my major in algorithms through the Internet and major books, and I was able to expand my knowledge deeply and broadly by visiting my professor and showing him the blueprint of the algorithm I think. These efforts gave me a holistic view of the IT industry, and I have acquired knowledge of the entire computer by hand drawing CPU design in the computer structure. My lifetime goal is to believe in myself to be able to say that I am confident in what I am capable of doing. When I was in the fourth grade of college and was in the midst of interest in majoring in computer engineering and IT, I focused on employment and graduate school, and aligned myself with IT. \"I will do it because it is what I can do.\" What people usually say before starting a job is usually concluded that the job is difficult and difficult because of what it is like. At the same time, I often give others the sense of failure in advance because I will fail. Since I was young, I have lived with positive consideration with my family. My father manages scrap metal in a hardware store. Whenever I replace my father\\'s errand, I talk to the elderly who carry scrap metal and pull the rear car together. Although I was about the same age as a middle school student, I had a habit of helping with my father. My mother, who worked in a restaurant for decades, always told me to develop consideration for my family and others. As a Korean F.I.S. person, I will deal with all situations positively with fun difficulties if there are difficulties and creative ease if there are any.I will work hard to develop the smart finance industry beyond the development of our own. It is positive that has made my achievement experience prosperous. I have gained achievement experience in various fields by working in a lab for 7 years at a university and graduate school, and part-timer at a coffee shop and headhunting company for 4 years. As an intern, I had experience working on Android development projects with my creativity. It is about understanding the strengths of my team members. I think \"Is the connection right\" is the core of the biggest social issue. The biggest example is the Fourth Industrial Revolution in the industry. Starting with smartphones, new terms such as ICT, big data, and connected cars poured out in the IT world, and accordingly, large companies began to expand their roles, SMEs began to expand their work, and new venture companies began to grow indiscriminately. However, while these growth and revolutions seem to be going in a good direction in the world, it is true that there are no real results in Korea. It is necessary to properly investigate the actual conditions of technologies centered on the connections that Korea has. I think that the cooperation of companies is becoming the most important accordingly. I think that our FIS should be a first mover, that is, a leading point, more than a follower through the development and operation of the financial industry. To control the model through programming, I had continuous conversations with my team members, and I was able to show the safe movement of the device through logical algorithm design while modifying the code repeatedly. When I was in college, I encountered security in the Internet security lab and experienced the convenience of applications through Android apps. Our FIS will increase the driving force to lead the Nth Industrial Revolution beyond the 4th industry in Korea.', '0'], [\"As an intern, I had the experience of using my membership to carry out an Android development project. I was attached to the team and first suggested to two other intern members that they develop an app using GPS-related technology in Android, and I started the project development. However, my team member had a difficulty in that he had no experience in developing the technology called Android. Since all the strengths of the team members were different, I found an open-source project necessary to carry out the development as a member of the team and conducted a self-study with the team members after work. In addition, for the success of the team project, I asked the development team for help to receive feedback on the source code and the speed of running the program. As a result, I completed the intern project and received praise while shaking hands with the intern president. I gained social experience in various fields by working in the lab for 7 years at a university and graduate school, and part-timer at a coffee shop and headhunting company for 4 years. While conducting research on the radio wave model in my graduate thesis, I was immersed in the radio wave research. In addition, while studying the frequency usage status and wireless mobile communication technology such as mobile and vehicle in the wireless vehicle communication lab, I became interested in the status of Korean mobile communication. While talking to people in various fields, the center of my conversation has always been positive and led to good results. I got a good teamwork while working on the project in my university lab, and I was able to complete the first year of the project I was assigned to in graduate school. The future industry will be an era of convergence industries in which the gas facilities of the Korea Gas Stabilization Corporation and the gas industries of smart cars, mobile cars, medicine, and energy are merged. Rather than my own technological prowess, I will strive to develop the technological prowess of the Korea Gas Safety Corporation and expand the Korea Gas Safety Corporation's business that is more advanced for the satisfaction of the public at home and abroad. And what is important is also an important internal goal to become an executive of the Korea Gas Safety Corporation in the long run, planning and supervising the system so that I can lead the optimization of the smart ICT industrial environment. [Engineering Concerns and Exploration through Personality] The competencies that I feel most important while working on a project in the vehicle communication laboratory of the graduate school are personality such as positive attitude, correct personality, and smooth interpersonal relationships. I often worked with other teams, such as sharing test results with the Automotive Parts Research Institute, collaborating with research support teams, cooperating with other schools' laboratories, coordinating and developing work with researchers related to radio wave model projects that I have been in charge of since the second semester of graduate school. Since vehicle communication was the main field of study in graduate school, it was natural that knowledge, motivation, and major knowledge of wireless communication applied to vehicles were important, and I felt that the most important competency while actually taking charge of a project in the lab was personality, such as a positive attitude, correct personnel, and smooth interpersonal relationships. While working on a project with other teams, I studied on my own and learned what I did not know with a sense of ownership and enthusiasm from my seniors. With curiosity about the results of radio wave model simulation, I found and studied what I did not know by analyzing, modifying, and simulating the codes of my seniors. Through this process, I was able to inspire myself with constant motivation while maintaining passion and curiosity. The safety service application that I have developed has been able to expand my research by being used as a cornerstone of an application for safety services that is being actively studied both at home and abroad in the vehicle communication laboratory where I graduated. Rather than focusing only on me, I will make an engineering contribution through cooperation for the public safety, which is a common goal as a Korea Gas Safety Corporation, by developing engineering design capabilities cultivated by me through cooperation through team project design subjects and basic computer knowledge through engineering certification. Through my experience, I will operate a complete quality product customized for customers through a preliminary inspection of the information system of the Korea Gas Safety Corporation, which is directly related to the convenience and safety of customers. [Target-tailored development for perfect quality products] In the second semester of graduate school, I developed a safety service application for accurate vehicle communication simulation using Java programming. In order to cooperate with the Korea Automotive Parts Research Institute, which was the main target for the application, and the laboratory using actual vehicles of other universities, we started the development by comparing dozens of parameters and requirements. Since the main purpose of the application was an application for safety services, I studied the safety services currently being studied in advance, and studied additional proposed or modified parameters in academic societies and papers, and continued to study what is the most important point of safety services and what kind of companies are the main target groups. For example, another university that conducted research together requested research assistance on safety services, and I shared the research contents on the forward collision prevention system and the emergency collision prevention system among the safety services that I had been continuously researching. As I shared the research, I began to see improvements in the safety service applications that I had previously developed in my lab. It was regrettable that the development intention was not clear and above all, the results of the research could not be clearly shown because the existing application was to receive values from the simulation and display them on the screen while the vehicle was stopped. Based on these improvements, I used Java programming to show on the screen the location coordinates of one's own car and another's vehicle, the vehicle speed, etc., which were values received from the network simulator, while also making additional improvements so that the vehicle's location can be seen moving together according to the moving coordinate values. These improvements allowed other teams to conduct research by using the safety service application developed in our lab, first conducting the simulation, locating the vehicle, and helping to efficiently design the simulation from the actual vehicle. [A leader in the safety industry] I graduated from the Department of Electronic Computer and Communication Engineering.I have personally been interested in the connection between the gas safety corporation's infrastructure and the integrated safety industry while leading radio wave model research with my graduation thesis. So I applied to the Korea Gas Safety Corporation, which is a leader in the next generation of gas safety technology. I was fascinated by algorithms for hardware and software when I was in college and graduate school, and I completed logical circuit design, algorithms, industrial mathematics, and discrete mathematics for logical algorithms. I designed the algorithm for the products that have already been released, and I later planned and operated an information system related to gas safety so that everyone can use gas more safely or live a convenient life through the system I designed.\", '0'], [\"[Student-Motivation] After working part-time at coffee shops, headhunting companies, and family restaurants for four years since I was an adult, I realized the importance of talking with people in various fields and the need for consideration. At universities and graduate schools, I was able to be reborn as caring seniors and juniors among my friends, and I was able to positively motivate everyone by saying that I was always able to do team projects. [Result of Action] I had experience working on Android development projects with my membership. I was attached to the team and first suggested to two other intern members that they develop an app using GPS-related technology on Android, and I started developing the project. However, my team member had a difficulty that they had no experience in developing Android technology. Since all the strengths of the team members were different, I found an open-source project needed to carry out the development as a member of the team and conducted a self-study after work with them. Also, for the success of the team project, I was able to ask the development team for help and get feedback from the staff. As a result, I was praised when I shook hands with the intern. [Personality-Positive] It is the affirmation that has made my social experience prosperous. I have gained social experience in various fields by working in a lab for 7 years at a university and graduate school, and part-timer at a coffee shop and headhunting company for 4 years. While talking to people in various fields, the center of my conversation has always been positive, and I have led to good results. I got a good teamwork while working on the project in my university lab, and I was able to complete the first year of the project I was assigned to in the graduate school and extend it to the second year. [Target-tailored development for perfect systems] The safety service application that I developed in my second semester of graduate school was used as a cornerstone of an application for safety services that has been actively studied both at home and abroad in the vehicle communication lab where I graduated, and I was able to expand my research. Recently, the importance of building and operating customized systems is increasing. I think what I can do to solve the inconvenience is to supplement the system through the knowledge of computer structure. While studying computer structure and Internet security, I am making efforts to consider the safety and efficiency of the system. [Motivation for application - Center of Eastern Finance] I applied to FIS System because I thought that FIS System was the safety net that managed the most important money for OO Group customers. While studying vehicle security in the lab, I was interested in financial security that was directly related to the customer's money, and my main motivation for application is to research and develop the core financial system in FIS System. [Up-Safety Application] When I was a university student, I encountered security in the Internet security lab and experienced the convenience of applications through the Android app. I also learned the applicability and scalability of security while taking an advanced security course in the graduate school lab. I thought that my job at FIS System was customized financial IT services. I will contribute my security research capabilities and application performance improvement capabilities to FIS System. [FIS-type talents] It is also important to become a FISIN who directly provides technical services to customers and enhances satisfaction. To this end, I will join FIS System and form a long-term team through continuous dialogue with seniors and colleagues. I will form a long-term team to speed up communication with customers and identify needs, and enhance the completeness of the project.\", '0'], ['[New Ideas Using Sensitivity and Carefulness] I am either oversensitive or overly cautious, and I am careful when speaking. To compensate for my shortcomings, I always act passionately with new goals. I have a habit of taking notes while carrying a ballpoint pen and notebook to check myself. When I was in college, I became curious as I participated in a college programming competition, and I developed logical sensitivity and passion. When I was in graduate school, I created ideas with researchers while exploring academic papers and overseas journals for new ideas related to vehicle communication, and I was able to contribute to ideas related to simulation and modeling. As a researcher of Korean energy technology, I will contribute to the research and development of information technology that can generate new and certain profits in the N-cha industry in the future through passionate brain activities and careful decisions. When I was a freshman in college, I took an engineering certification course and acquired basic design and development capabilities to become a talented person at the Korea Institute of Energy Technology in the future. I acquired basic knowledge such as physics and mathematics for efficient software design, and I wanted to design and operate devices with the team while taking design courses such as engineering design, system analysis, and design. I tried to find a point of contact through the enjoyment of communicating with the other party, interest in new information technology, and the convergence of my computer engineering knowledge, and I targeted my business with the goal of becoming a researcher of convergent IT Korean energy technology. Through the cooperation I learned in the team project design and the acquisition of algorithmic knowledge in the engineering certification, I developed the engineering design competency cultivated for me. That\\'s why I applied to the Korea Institute of Energy Technology because I believe that my ability to capture customer needs through communication with researchers and provide services accordingly will be the most necessary foundation for the Korea Institute of Energy Technology\\'s actions as the number one researcher that customers love. I think that [Is the connection right] is the core of the biggest social issue. The biggest example is the Fourth Industrial Revolution in the industry. Starting with smartphones, new terms such as ICT, big data, and connected cars poured out in the IT world, and as a result, large companies\\' roles were expanded, SMEs\\' workplaces were expanded, and new venture companies began to grow indiscriminately. However, while these growth and revolutions seem to be going in a good direction in the world, it is true that there are no real results in Korea. It is necessary to properly investigate the actual condition of the technologies centered on the connections that Korea has. I think that the cooperation of companies is becoming the most important. I think the Korea Institute of Energy Technology should be the first movers, or leaders, more than followers, through energy R&D. In order to control the model through programming, we had continuous conversations with our team members, and we were able to modify the code repeatedly and display safe movement of the device through logical algorithm design. The university\\'s Internet Security Lab managed Windows and Ubuntu servers. He was in charge of user management and computer virus and physical security management in detail, and through this experience, the graduate school\\'s lab managed file servers and integrated mail servers. For the accessibility and safety of management, all information was distributed and managed on hard disks, other computers, and the cloud, and anyone could access the information at any time. When I was a senior at university, I applied the concept of OTP to FTP application as a graduation thesis, and the graduate school developed a vehicle safety service application using Java. When I was in college, I encountered security in Internet security labs and experienced the convenience of applications through Android apps. The Korea Institute of Energy Technology will increase the driving force to lead the Nth Industrial Revolution beyond Korea\\'s Fourth Industrial Revolution. [Extreme Development Beyond 20 Times] Bruce Ekel, the author of \"Thinking in Java\" among Java books, said that the difference in productivity is more than 20 times depending on whether the algorithm is used properly. I am making continuous efforts to equip myself with the capabilities tailored to the convergence of hardware and software to create higher productivity through cooperation with Korean energy technology researchers as well as synergy with Korean energy technology researchers. Based on the experience of programming in the Linux development environment since college, I have continuously gained experience between hardware and software by displaying pictures on embedded equipment in the Linux environment in graduate school. In order to continue to develop in the field of computing, which is the basis of my capabilities, I have taken actions to solve algorithmic competition problems since college, and I have laid the foundation for computer knowledge through mathematics courses through differential calculus and engineering certification. When I was developing a calendar application in college, I doubted my team and I to find out the difference from existing applications. However, I collected open-source projects and characteristic analysis of existing applications for three days until 10 p.m. with my team members to make doubts a joint success. As a result, I was able to turn doubts into excellent grades such as A and improved trust with my team members. In order to continuously modify and improve simulations, the graduate school is making efforts not to miss the detailed basics while studying algorithm problem-solving strategy books, with the ability to draw algorithmic design using modeling languages on backpapers. To this end, I will join the Korea Institute of Energy Technology and form a long-term team through continuous conversations with seniors and colleagues. As a researcher of Korea Energy Technology, I would like to be a mock-up of the Korea Institute of Energy Technology because I want to show my dreams to someone through technological skills and reveal all parts of society. [There is no impossibility in endless efforts] My efforts include the ability to become a simple overcoming talent. In college, I completed software-related algorithms, programming, object orientation, and computer structure, and additionally completed basic mathematics and physics for the efficiency of algorithms.Through my major in system analysis design, I developed the ability to design the big picture of software using software programs. At first, I lacked knowledge, but I expanded my major in algorithms through the Internet and major books, and I was able to expand my knowledge deeply and broadly by visiting the professor and showing him the blueprint of the algorithm I think. These efforts gave me a holistic view of the IT industry, and I acquired knowledge of the entire computer by hand drawing CPU design in the computer structure. My lifetime goal is to believe in myself to say that I can do what I am confidently. When I was in the fourth year of college and was interested in my major in computer engineering and IT, I agonized over employment and graduate school. Professors and seniors and juniors around me worried that it would be difficult to adapt and even fail if I went to another graduate school. However, in my head, I had a strong belief that I could do it. When I was in my fourth year of college, I believed that I would be an information technician of the Korea Institute of Energy Technology for the next 10, 20 years and the rest of my life. For my short-term tasks such as going to graduate school and graduating, I researched wireless communication trends, which were my areas of interest, and now I am continuing my efforts as a computer while carrying out the Java Open Source project. When I was in graduate school, I was able to realize the practicality of knowledge through professional research on vehicle communication networks, and as I proceeded with the business, I acquired additional capabilities in algorithm modeling. [I will do it because it is something I can do]. What people usually say before starting a job is usually concluded that the job is difficult and difficult because of what it is. At the same time, they often give others the sense of failure in advance because they will fail. Since I was a child, I have lived with positive consideration for my family. My father manages scrap metal in a hardware store. Every time I replaced my father\\'s errands, I talked to the elderly who carried scrap metal and pulled a rear car with him. Although I was as young as a middle school student, I had a habit of helping along with him. My mother, who had worked in a restaurant for decades, always told me to develop consideration for my family and the other person. As a Korean energy technology researcher, I will respond positively to all situations with fun difficulties if there are difficulties and difficulties in the infrastructure for energy technology research. I will strive to develop the smart grid industry beyond the development of the Korea Institute of Energy Technology alone. It is positive that has made my achievement experience prosperous. I have gained achievement experience in various fields by working in the lab for 7 years at a university and graduate school, and part-timer at a coffee shop and headhunting company for 4 years. As an intern, I had experience working on an Android development project using my membership. Being attached to the team, I first suggested to two other intern members that they develop an app using GPS-related technology in Android, and I started developing the project. Since the strengths of the team members were all different, I found an open-source project necessary to carry out the development as a member of the team and conducted a self-study with the team members after work. While talking to people in various fields, the center of my conversation has always been positive, and I have led to good results. In the university lab, I got good teamwork by working on the project, and in the graduate school, I was able to complete the first year of the project I was in charge of and extend it to the second year.', '0'], ['\"Unstoppable Crisis for Development.\" There were constant crises in my growth to become what I am today in Semes. First, I started with my parents. As the car center your father was running wasn\\'t doing well, things went bad in his family, and eventually, he handed it over to someone else. My father became unemployed as a president. However, my father cheered up the way our family looked at it, and once again he bolstered to start working at a hardware store, and so far he has been running a wonderful hardware store. The second was when I was in college and contemplating computer science. I became interested in a field called computer science, and while I was on leave of absence, I thought about my major constantly as I gained social experience. I could imagine what I would be happy to do when I would later turn 40 or 50. But I say, I am committed to becoming a new employee of Semes and working with my colleagues to turn crises into opportunities and advance them. Bruce Ekel, the author of Thinking in Java, in his book \"Extreme Productivity Over 20 Times,\" says that depending on the proper use of the algorithm, productivity varies more than 20 times. I am continuously making efforts to equip myself with capabilities tailored to the convergence of hardware and software in order to create higher productivity through cooperation with Semes people. I have been interested in computer science since I was a college student by solving algorithmic competition problems for the continuous development of the computer field, which is the basis of my capabilities. I have worked part-time at coffee shops, headhunting companies, and family restaurants for four years since I was an adult, and I have realized the importance of talking with people in various fields and the need for consideration. It was the most meaningful activity to strengthen myself and constantly motivate myself while reading books about people I respect. \"New Ideas Using Sensitivity and Carefulness\" In my life, the incident began with the attack of weaknesses. My weaknesses are either oversensitive or overly cautious, and I am careful when speaking. To compensate for my weaknesses, I always act passionately with new goals. I have a habit of taking notes while carrying a ballpoint pen and notebook to check myself. When I was in college, I participated in a programming competition and became curious, and I developed logical sensitivity and passionate behavior. When I was in graduate school, I created ideas with researchers while exploring academic papers and overseas journals for new ideas related to vehicle communication while writing proposals, and I was able to contribute to ideas related to simulation and modeling. I used excessive sensitivity and prudence to come up with ideas in my head, but I was able to get quick problem-solving ideas through passionate brain activities and body movements. As a Semes person, I will contribute to the creation of new and certain profits in the semiconductor and display equipment industries through passionate brain activities and careful decisions. \"Division, harmony, flow of change\" As a college student, I liked to be active and exercise, and I worked as a soccer club and a coffee shop part-time in the lab. There were some difficulties while working at the same time as a lab activity and a part-time job for four years, but I had a great attachment, so I struggled with my body, but I acted responsibly. As the number of students in the lab increased to more than 30, individual responsibilities decreased, and problems arose as the number of students who did not participate increased. I suggested the division of labor to the lab students, and I tried to promote the importance of group activities such as general affairs, mentor mentee system, and cleaning, and efficiently carry out the activities in the lab. Due to my sensitive but passionate decision on laboratory activities, students actively participated and all worked in harmony. We will lead the change in global equipment quality competitiveness along with the Semes through proper division and harmony of our work. \"Is it connected properly?\" I believe that connection is the core of the semiconductor and display equipment industries. And I think connection is the core of the biggest social issue. The biggest example is the Fourth Industrial Revolution in the industry. Starting with smartphones, new terms such as ICT, big data, and connected cars poured out in the IT world, and accordingly, large companies began to expand their roles, SMEs began to expand their work, and new venture companies began to grow indiscriminately. Take the Internet, which was considered the best in the world. Korea is the fastest. However, for the 5G that is emerging, legislation and clear standards have not yet been properly designated, so it is common to follow international standards. Although it seems that there will be a new wind and hope in the industrial world as various measures have been taken, it is true that it is lacking technically and practically. What we need to look at here is the importance of connection. It is necessary to properly investigate the actual condition of the technologies that are centered on the connections currently in Korea. I think that the cooperation of companies is becoming the most important accordingly. Large companies accept new technologies when acquiring venture companies, but they must carefully examine how far they can go and acquire new technologies. Mid-sized companies and SMEs should focus their management capabilities on IT and focus on nurturing new human resources. Of course, these aspects are essential requirements for a company, regardless of its size. In addition, I think that Semes should be a first mover or a leader in new technologies through connection. Semes should build a driving force that can lead the Nth Industrial Revolution beyond the 4th industry in Korea. Future convergence talents like me will be needed at the center of it, and Semes should provide appropriate connections accordingly.', '0'], [\"[New Myth through Open Mind and Positive Thinking] In college, I completed algorithms, programming, object orientation, computer structure, etc. related to software, and additionally completed basic mathematics and physics for the efficiency of algorithms. Through my major in system analysis and design, I have developed the ability to design big pictures of software using software programs. I have continuously discovered possibilities through an open mind about learning, positive thoughts that I can do it, and endless efforts. Through the Internet and major books, I was able to expand my major competence in algorithms, and by visiting professors and showing them the design of algorithms I think, I was able to expand my knowledge deeply and widely. I was able to gain knowledge of algorithms, and in the computer structure, I acquired knowledge of the entire computer by drawing CPU design by hand. When I was in graduate school, I was able to realize the practicality of knowledge by professionally researching vehicle communication networks, how computer networks can be applied in real life, and I secured the ability to model algorithms while working on the project. [Action based on the thought of taking care of forests and trees] - Personality Keyword: 'Concrete Action.' The important point of my personality is the perspective of taking care of forests and trees. There are two important points of view when performing tasks. It is the same perspective as a forest looking at the whole, and the same perspective as a tree that can be divided in detail and continuously recognized and influenced. As a project researcher, I have practiced concrete actions through my strengths. To see the overall forest, I held meetings with master's researchers twice a week while conducting thesis seminars and watching open-source projects on the suitability and actual driving environment of the radio wave model, which were the goals of the project. In order to recognize the details and have a successful impact on the project results, the three masters involved in the project implementation were asked to perform the work of debugging their source codes themselves. [Student activities inside and outside the school] - OO University's Internet Security Lab, 2008.03.04~present, Seminar and mentoring in the lab - OO University's UNLab Lab, 2012.12.25~2015.01.31, project participation and group activities in the lab (academic, foot volleyball club) [part-time job experience] - OO City coffee shop (3 years, 7 months, 14 days), 2008.07.12~2012.028 Working - Marketing/sales part-time job at coffee shop [graduate project experience] - Project name: Evaluation of wireless communication and application services for cooperative vehicle safety system. - Establishment of certification infrastructure - Role: Project research assistant - In charge: Research and development of radio wave model for V2X (development of source code of radio wave model in network simulator), research on trends related to radio wave model using simulation, thesis - Participation in 3 other projects, writing 4 domestic papers (Korea Communications Association, etc.)\", '0'], [\"1. Planting Dreams Through Youth Foundation - Through volunteer activities to guide and learn low-income youth, I have decided that I want to make teenagers' dreams come true. 2. Joining a Korean Animal Protection Organization - Conserving the ecosystem through activities to protect endangered animals. 3. Software architecture consultant - Developer who can learn various IT skills and implement systems under any conditions. 1. Entrance to learn through tests and interviews to gain practical skills. 2. [Innovative Challenge] 3. Differentiated from the existing shopping malls, pre-payment and confirmation 3. completed the 800km path of pilgrims in 22 days by walking the path of the Spanish pilgrimage by myself. 1. Love for neighbors learned through my parents / When a fire broke out next to a store run by my parents, my parents were the first to step up and start a fundraising campaign. 2. San Fermin Festival in Spain / Famous for its cattle driving festival, I enjoyed the festival by socializing with people from various countries across borders and languages. 3. Christmas cake / I bought a Christmas cake for my family with my first salary I earned through a part-time job I encountered for the first time in my life. By implementing the first O2O service in the shopping mall, I pursued customer trust and convenience. As a result, returns and refunds were less than 4% compared to competitors, and I was selected as a nurturing start-up for SK Planet. 1. Book title: Software Master/Author: Sandro Mancuso / Reason: It made me realize that a developer is a person who should pursue creative activities like a single artist, not just a development factory production line. 2. Book title: Courage to be hated / Author: Ichiro Kishimi / Reason: It reminded me to have the courage to change myself if I want to flex my relationship with people around me. 3. Book title: Meet Me on the Santiago Road / Author: Hafe Kerkeling / Reason: This book has provided an opportunity for me to go on the path of pilgrimage, conscious of the evaluation of others. 1. Internet Address: Stack Overflow / Reason: Through this site, you can find ways to solve problems in development in various directions, not just one way. 2. Internet Address: Naver News / Reason: You can check domestic politics and payment news throughout the day, and access global news in real time. 3. Internet Address: YouTube / Reason: It is a refreshing web service that allows you to relieve the stress that you accumulated over the day through various content videos. [Canvas With Dreams] To me, I think the workplace is a canvas where I can draw my dreams to my heart's content. Before joining the company, if you have prepared for various colors of competency with your studies and various experiences, you will draw your dreams on the canvas of work by using various colors of competency. Just as the more diverse the colors, the more colorful the pictures become, I will try to draw dreams through various colors even after joining the company. [I will be an SE expert at E-Land Systems, which boasts the optimal distribution system] I think the key to E-Land's success based on its optimized system is its IT capabilities. I am confident that E-Land Systems, which is in charge of E-Land's enterprise-wide management through differentiated IT solutions and new technologies, is an optimized company that I can contribute to E-Land. I studied Green IT, Smart Grid, Big Data, and Beacon with great interest to understand the rapidly changing flow of the IT market. In particular, while working as an intern at a company whose main business is LTE communication solutions, I was able to directly experience home network technology by participating in a smart meter project that measures the power consumption of each household and transmits data to electric companies through LTE signals. In the future, we have supported to become an SE that can provide growth for E-Land Systems by creating an E-Land network solution that can be integrated into the store management and distribution sectors. [I will be an SE expert at E-Land Systems, which boasts an optimal distribution system] I think the key to E-Land's success based on its optimized system was its IT capabilities. E-Land Systems, which is in charge of E-Land's enterprise-wide management through differentiated IT solutions and new technologies, is the optimized company that I can contribute to E-Land. I studied with great interest in green IT, smart grid, big data, and Beacon to understand the rapidly changing trend of the IT market. In particular, I was able to experience home network technology firsthand by working as an intern at a company whose main business is LTE communication solutions, by participating in a smart meter project that measures the power consumption of each home and transmits data to electric companies through LTE signals. I have supported to become an SE that can provide growth of E-Land Systems by creating E-Land network solutions that can be applied to store management and distribution in the future. [The spirit of pioneering the creation of something out of nothing] To describe myself in one word, I am a person who practices something out of nothing. In other words, creating something out of nothing, focusing on what others have not come up with, and putting it into action in order to realize it. Since I was young, I used to draw pictures of future undersea cities, food, and fashion that others could not have imagined. Seeing my paintings, people around me were surprised and praised me for having unique ideas at the same time. I became interested in programming that allowed me to express my unique ideas freely as if I were drawing on canvas, and naturally went on to major in computer science. [Challenge 'first' through 'discrimination'] As a first step toward surprising the world with unique ideas, I started a fashion shopping mall called 'OO.'It was intended to provide the trust and convenience of customers through the rather unconventional operation method of 'pre-check and payment' which is differentiated from the operation method of the existing shopping mall called 'pre-payment and confirmation'. In addition, through the concept of personalized styling service, we tried to be competitive with existing shopping malls, and targeted niche markets by selecting men rather than women as our main customer base. Naturally, this became the first in the shopping mall industry to realize individualized O2O styling service for men, and returns and refunds have occurred at an average rate of 4% lower than competitors. Based on these results, we were able to get an opportunity to be selected as a nurturing start-up company for oo. [Leaving one's feet to find team members] We wanted to unite with people from various fields for the professional operation of the fashion shopping mall. We wanted to form a college student start-up team consisting of various majors such as business administration for the operation of shopping malls, fashion design department in charge of stylists and MDs, and media design department in charge of the design and design of UX/UI of service apps. In order to gather team members in each field, I ran on my feet, posted a talent recruitment poster on the bulletin board of the university student center, and posted a recruitment announcement on the online bulletin board of the major of various universities. After seeing the recruitment announcement, I was able to meet the students who contacted me in person to confirm the applicant's passion for starting a business. Through this, we were able to form passionate team members to lead OO. [Communication to achieve 'communication' through 'communication'] After the formation of the team, I tried to create better services through smooth communication with each team member. As the developer in charge of me, I did not pay attention only to development work, but talked a lot with the planner to understand the service function and the intention of planning, and discussed a lot of time with the designer for efficient UX/UI. Above all, I tried to improve the service process by grasping what inconveniences customers feel through conversations with stylists who actually face-to-face with customers and what difficulties the stylists felt in face-to-face with customers. E-Land Systems will take the lead in realizing the Digital Innovation that E-Land Systems dreams of by demonstrating the 'challenge', 'pioneering spirit' gained through start-ups, and 'communication ability' that can radiate synergy effects of team members.\", '0']]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "with open('total.csv', 'r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a137ad-09d8-414b-8d36-467030026788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data1 = data.rename(columns=data.iloc[0])\n",
    "data2 = data1.drop(data1.index[0])\n",
    "data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6d5ee0-2671-4068-ab9e-52d34af788a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['text'].astype(str).tolist()\n",
    "labels = data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4401030b-efd2-4acd-b498-cd04c9d7ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbfe92d6-aef1-4963-a4ed-425f3ab5d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9765e5-a0b7-42f9-bce3-3b81dc97ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i ,doc in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e7ed19-569b-4e51-9ef1-da3201d6b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec(\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    epochs=40,\n",
    "    dm=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7b9cf8-b548-4f57-a4ab-e97f03b30368",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples = doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc52e4df-a08b-4e7f-a865-e71449057791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=123)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train_vectors = [doc2vec_model.infer_vector(word_tokenize(doc.lower())) for doc in X_train]\n",
    "X_test_vectors = [doc2vec_model.infer_vector(word_tokenize(doc.lower())) for doc in X_test]\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "classifier.fit(X_train_vectors, y_train)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9aadb3-845c-417a-86df-023447a45007",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c216b578-4145-42e2-9b45-6b35771faffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.86      0.67      0.67         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ba951e-347c-49a2-84e3-ae89927e60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31bc50bc-b667-4c29-ad4e-8e826ed74ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a945a5-a8c8-40ad-a440-63eaaa1b58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [100,200,300],\n",
    "    'max_depth': [10,20,30],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf':[1,2,4],\n",
    "    'max_features':['sqrt','log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b1b6eb4-864b-4ff0-ae12-e9882909ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid= param_grid,\n",
    "                           cv=5,\n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c49a80f-65d8-437b-b84e-cdb7535fc934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={&#x27;max_depth&#x27;: [10, 20, 30],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={'max_depth': [10, 20, 30],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9272782-6cf9-4346-aa34-4625015b2569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff94a838-e9cb-48ca-a4ff-d74289b1ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2f308d-431c-4df1-980f-3b12ed35ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.86      0.67      0.67         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c3883d-c52c-47fa-8567-7781c6c71cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6121d889-1ad5-4e42-bf3d-83430a8dab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f393f84-bb67-4fbd-8287-24a197c6aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators':randint(100,500),\n",
    "    'max_depth': randint(10,50),\n",
    "    'min_samples_split': randint(2,11),\n",
    "    'min_samples_leaf': randint(1,5),\n",
    "    'max_features':['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed30cd4-ab33-4979-9266-7f87aac89733",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=3,  random_state=123, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ad51948-8055-4467-9ed1-85d0b5632a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=117; total time=   0.0s\n",
      "[CV] END max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=117; total time=   0.0s\n",
      "[CV] END max_depth=12, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=117; total time=   0.0s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=324; total time=   0.2s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=324; total time=   0.2s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=324; total time=   0.2s\n",
      "[CV] END max_depth=35, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=196; total time=   0.1s\n",
      "[CV] END max_depth=35, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=196; total time=   0.1s\n",
      "[CV] END max_depth=35, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=196; total time=   0.1s\n",
      "[CV] END max_depth=26, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=102; total time=   0.0s\n",
      "[CV] END max_depth=26, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=102; total time=   0.0s\n",
      "[CV] END max_depth=26, max_features=sqrt, min_samples_leaf=2, min_samples_split=9, n_estimators=102; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=147; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=147; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=147; total time=   0.0s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=458; total time=   0.3s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=458; total time=   0.3s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=458; total time=   0.3s\n",
      "[CV] END max_depth=43, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=176; total time=   0.0s\n",
      "[CV] END max_depth=43, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=176; total time=   0.1s\n",
      "[CV] END max_depth=43, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=176; total time=   0.0s\n",
      "[CV] END max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=431; total time=   0.3s\n",
      "[CV] END max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=431; total time=   0.3s\n",
      "[CV] END max_depth=13, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=431; total time=   0.3s\n",
      "[CV] END max_depth=44, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=305; total time=   0.2s\n",
      "[CV] END max_depth=44, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=305; total time=   0.1s\n",
      "[CV] END max_depth=44, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=305; total time=   0.2s\n",
      "[CV] END max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=170; total time=   0.0s\n",
      "[CV] END max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=170; total time=   0.0s\n",
      "[CV] END max_depth=28, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=170; total time=   0.0s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=459; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=459; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=459; total time=   0.3s\n",
      "[CV] END max_depth=21, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=143; total time=   0.0s\n",
      "[CV] END max_depth=21, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=143; total time=   0.0s\n",
      "[CV] END max_depth=21, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=143; total time=   0.0s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=412; total time=   0.2s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=412; total time=   0.3s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=412; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=151; total time=   0.0s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=151; total time=   0.0s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=151; total time=   0.0s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=167; total time=   0.0s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=167; total time=   0.0s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=167; total time=   0.0s\n",
      "[CV] END max_depth=21, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=21, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=21, max_features=log2, min_samples_leaf=2, min_samples_split=9, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=322; total time=   0.2s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=322; total time=   0.2s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=322; total time=   0.2s\n",
      "[CV] END max_depth=16, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=477; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=477; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=477; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=466; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=466; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=466; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=293; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=293; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=293; total time=   0.2s\n",
      "[CV] END max_depth=26, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=146; total time=   0.0s\n",
      "[CV] END max_depth=26, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=146; total time=   0.0s\n",
      "[CV] END max_depth=26, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=146; total time=   0.0s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=356; total time=   0.2s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=356; total time=   0.2s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=356; total time=   0.2s\n",
      "[CV] END max_depth=45, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=424; total time=   0.3s\n",
      "[CV] END max_depth=45, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=424; total time=   0.3s\n",
      "[CV] END max_depth=45, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=424; total time=   0.3s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=160; total time=   0.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=160; total time=   0.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=160; total time=   0.0s\n",
      "[CV] END max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END max_depth=11, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END max_depth=17, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=241; total time=   0.1s\n",
      "[CV] END max_depth=17, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=241; total time=   0.1s\n",
      "[CV] END max_depth=17, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=241; total time=   0.1s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=219; total time=   0.1s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=219; total time=   0.1s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=219; total time=   0.1s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=472; total time=   0.3s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=472; total time=   0.3s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=472; total time=   0.3s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=165; total time=   0.0s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=165; total time=   0.0s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=165; total time=   0.0s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=176; total time=   0.1s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=176; total time=   0.1s\n",
      "[CV] END max_depth=40, max_features=sqrt, min_samples_leaf=1, min_samples_split=9, n_estimators=176; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=log2, min_samples_leaf=3, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=347; total time=   0.2s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=347; total time=   0.2s\n",
      "[CV] END max_depth=23, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=347; total time=   0.2s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=103; total time=   0.0s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=103; total time=   0.0s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=103; total time=   0.0s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=297; total time=   0.2s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=297; total time=   0.2s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=297; total time=   0.2s\n",
      "[CV] END max_depth=43, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=246; total time=   0.1s\n",
      "[CV] END max_depth=43, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=246; total time=   0.1s\n",
      "[CV] END max_depth=43, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=246; total time=   0.1s\n",
      "[CV] END max_depth=45, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=173; total time=   0.0s\n",
      "[CV] END max_depth=45, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=173; total time=   0.1s\n",
      "[CV] END max_depth=45, max_features=sqrt, min_samples_leaf=4, min_samples_split=8, n_estimators=173; total time=   0.0s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=494; total time=   0.3s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=494; total time=   0.3s\n",
      "[CV] END max_depth=27, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=494; total time=   0.3s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=13, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=199; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=199; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=199; total time=   0.1s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=412; total time=   0.3s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=412; total time=   0.3s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=412; total time=   0.3s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=169; total time=   0.0s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=169; total time=   0.1s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, n_estimators=169; total time=   0.1s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=110; total time=   0.0s\n",
      "[CV] END max_depth=46, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=379; total time=   0.3s\n",
      "[CV] END max_depth=46, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=379; total time=   0.3s\n",
      "[CV] END max_depth=46, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=379; total time=   0.3s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=7, n_estimators=405; total time=   0.3s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=7, n_estimators=405; total time=   0.3s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=3, min_samples_split=7, n_estimators=405; total time=   0.3s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=286; total time=   0.3s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=286; total time=   0.2s\n",
      "[CV] END max_depth=33, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=286; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=345; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=345; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=345; total time=   0.2s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=215; total time=   0.1s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=215; total time=   0.1s\n",
      "[CV] END max_depth=42, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=215; total time=   0.1s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=325; total time=   0.2s\n",
      "[CV] END max_depth=49, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=489; total time=   0.3s\n",
      "[CV] END max_depth=49, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=489; total time=   0.3s\n",
      "[CV] END max_depth=49, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=489; total time=   0.4s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=315; total time=   0.2s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=315; total time=   0.2s\n",
      "[CV] END max_depth=19, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=315; total time=   0.2s\n",
      "[CV] END max_depth=31, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=144; total time=   0.0s\n",
      "[CV] END max_depth=31, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=144; total time=   0.0s\n",
      "[CV] END max_depth=31, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=144; total time=   0.0s\n",
      "[CV] END max_depth=38, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=483; total time=   0.3s\n",
      "[CV] END max_depth=38, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=483; total time=   0.3s\n",
      "[CV] END max_depth=38, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=483; total time=   0.3s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=180; total time=   0.1s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=180; total time=   0.1s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=180; total time=   0.1s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=227; total time=   0.1s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=227; total time=   0.1s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=227; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=104; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=104; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=7, n_estimators=104; total time=   0.0s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=454; total time=   0.3s\n",
      "[CV] END max_depth=28, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=158; total time=   0.0s\n",
      "[CV] END max_depth=28, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=158; total time=   0.0s\n",
      "[CV] END max_depth=28, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=158; total time=   0.1s\n",
      "[CV] END max_depth=48, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=273; total time=   0.1s\n",
      "[CV] END max_depth=48, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=273; total time=   0.2s\n",
      "[CV] END max_depth=48, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=273; total time=   0.1s\n",
      "[CV] END max_depth=32, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=391; total time=   0.3s\n",
      "[CV] END max_depth=32, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=391; total time=   0.2s\n",
      "[CV] END max_depth=32, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=391; total time=   0.2s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=443; total time=   0.3s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=443; total time=   0.3s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=443; total time=   0.3s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=393; total time=   0.2s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=393; total time=   0.2s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=393; total time=   0.3s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=263; total time=   0.1s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=263; total time=   0.1s\n",
      "[CV] END max_depth=11, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=263; total time=   0.1s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=181; total time=   0.1s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=181; total time=   0.1s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=2, min_samples_split=7, n_estimators=181; total time=   0.1s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=31, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=192; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=192; total time=   0.1s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=192; total time=   0.1s\n",
      "[CV] END max_depth=48, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=48, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=48, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=24, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=137; total time=   0.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=456; total time=   0.3s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=456; total time=   0.3s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=456; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=434; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=434; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=log2, min_samples_leaf=2, min_samples_split=3, n_estimators=434; total time=   0.3s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=359; total time=   0.2s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=359; total time=   0.2s\n",
      "[CV] END max_depth=16, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=359; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=7, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=7, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=7, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=29, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=114; total time=   0.0s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=477; total time=   0.3s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=477; total time=   0.3s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=477; total time=   0.4s\n",
      "[CV] END max_depth=42, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=435; total time=   0.3s\n",
      "[CV] END max_depth=42, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=435; total time=   0.3s\n",
      "[CV] END max_depth=42, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=435; total time=   0.3s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=4, min_samples_split=7, n_estimators=258; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=491; total time=   0.3s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=323; total time=   0.2s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=323; total time=   0.2s\n",
      "[CV] END max_depth=23, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=323; total time=   0.2s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=log2, min_samples_leaf=1, min_samples_split=3, n_estimators=235; total time=   0.1s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=291; total time=   0.2s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=291; total time=   0.2s\n",
      "[CV] END max_depth=47, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=291; total time=   0.1s\n",
      "[CV] END max_depth=46, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=46, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=46, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=425; total time=   0.3s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=377; total time=   0.2s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=377; total time=   0.2s\n",
      "[CV] END max_depth=24, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=377; total time=   0.3s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=348; total time=   0.3s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=348; total time=   0.2s\n",
      "[CV] END max_depth=38, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=348; total time=   0.2s\n",
      "[CV] END max_depth=41, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=41, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=41, max_features=log2, min_samples_leaf=3, min_samples_split=9, n_estimators=381; total time=   0.2s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=452; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=452; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=452; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=457; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=457; total time=   0.3s\n",
      "[CV] END max_depth=22, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=457; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=257; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=257; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=257; total time=   0.1s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=343; total time=   0.2s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=343; total time=   0.2s\n",
      "[CV] END max_depth=19, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=343; total time=   0.2s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=333; total time=   0.2s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=333; total time=   0.2s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=333; total time=   0.2s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=205; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=205; total time=   0.1s\n",
      "[CV] END max_depth=37, max_features=sqrt, min_samples_leaf=3, min_samples_split=9, n_estimators=205; total time=   0.1s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=240; total time=   0.1s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=240; total time=   0.1s\n",
      "[CV] END max_depth=17, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=240; total time=   0.1s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=408; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=408; total time=   0.3s\n",
      "[CV] END max_depth=36, max_features=sqrt, min_samples_leaf=4, min_samples_split=9, n_estimators=408; total time=   0.2s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=308; total time=   0.2s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=308; total time=   0.2s\n",
      "[CV] END max_depth=25, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=308; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=395; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=395; total time=   0.2s\n",
      "[CV] END max_depth=12, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=395; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=129; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=129; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=129; total time=   0.0s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=132; total time=   0.0s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=132; total time=   0.0s\n",
      "[CV] END max_depth=34, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=132; total time=   0.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=9, n_estimators=213; total time=   0.1s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=123; total time=   0.0s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=123; total time=   0.0s\n",
      "[CV] END max_depth=18, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=123; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=123),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF63DC10&gt;,\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF87DE90&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF996B90&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283B39D44D0&gt;},\n",
       "                   random_state=123, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=123),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF63DC10&gt;,\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF87DE90&gt;,\n",
       "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF996B90&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283B39D44D0&gt;},\n",
       "                   random_state=123, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=123),\n",
       "                   n_iter=100,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF63DC10>,\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF87DE90>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283CF996B90>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000283B39D44D0>},\n",
       "                   random_state=123, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4e2e5f-e41e-4606-a554-c0d7600c3a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 35, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 196}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48ebcdc-e816-4049-9e52-df0f7e07005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.92      0.83      0.85         8\n",
      "weighted avg       0.90      0.88      0.87         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = random_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_vectors)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ba4b4-14ce-4801-b616-527cc0d4d101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e957f3-6c62-4baf-af33-e2331e11b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
