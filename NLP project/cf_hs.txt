<데이터 준비>
'1. essay_url_crawling.ipynb'로 개발·데이터(지원분야) 자소서 중 전문가 분석이 완료된 323개를 평점 높은 순으로 가져와서  urls.csv 파일로 저장
 cf. page 9 18번째 자소서까지 평점 3점이고, 그 이후는 평점 1~2점 :
  평점 3점이 넘는 자소서의 갯수 : 178개 (페이지 없음 : 3개 -> 175개)
  평점 1~2점 자소서의 갯수 : 145개 (페이지 없음 : 3개 -> 142개)

'2. url_kr_cv_3.ipynb'로 161번째부터 240번째까지의 자소서들의 url을 가지고 와서 크롤링(한국어) 후 crawled_data.txt로 내용 확인 및 crawled_data0.csv를 만들고 crawled_data1.csv로 전처리 완료
 cf. 문제점 1 해결을 위한 join 함수 추가
  crawled_data0.csv 파일을 가지고 영어로 번역을 시도하였으나, 자소서 단위가 아닌 문단 단위로 번역이 되어 join 함수를 사용
 cf. 문제점 2 해결을 위한 3000자 이상 자소서 확인 / 6000자 
  파파고 홈페이지에서 번역을 시도할 때, 3000자까지밖에 한 번에 입력이 되지 않음

'3. kr_to_eng_crawling.ipynb'에서 한글로 가져온 자소서 80개를 영어로 번역 후 completed.csv에 저장 (크롤링 완료)
 cf. 189번째 자소서는 영어 자소서여서 completed.csv에 한글로 저장이 됨. merge 과정에서 영어로 수정

'4. word_cloud_first_hs.ipynb'에서 정규화를 거친 후 워드 클라우드를 사용하여 자주 사용된 단어들을 가시성 있게 요약

'5. over 6k check.ipynb'에서 수집한 한국어 자소서 317개의 길이를 검사 :
 6000자가 넘는 자소서가 2개 발견(52행, 62행 > 62행은 6002자로 번역에 문제가 없으나 52행은 6675자로 추가 작업이 필요)

'6. d2v_mchlrn_v1.ipynb'에서 첫 번째 모델 생성
 평점 1을 받은 자소서 : 15개 + 평점 5를 받은 자소서 : 22개 > accuarncy : 0.88
 cf. 데이터 양이 너무 작음

 '6-1. d2v_mchlrn_v1.1.ipynb'에서 두 번째 모델 생성
 평점 1과 2를 받은 자소서 : 142개 + 평점 4와 5를 받은 자소서 : 77개 > accuarncy : 0.82
 cf. 평점 2를 받은 자소서의 숫자가 너무 많아 data set의 불균형 초래

'7. d2v_mchlrn_v2.ipynb'에서 두 번째 모델 이용
 평점 1과 2를 받은 자소서 : 77개 + 평점 4와 5를 받은 자소서 : 77개 > 0.81

'8. RegressorModel.ipynb'에서 회귀 첫 번째 모델 생성
 평점 1~5를 사용한 모델에서는 결과가 너무 좋지 않아 3을 제외하고 모델을 만들어 보았으나 여전히 성능이 낮게 나옴
 RSME : 0.95 , R² Score: 0.37


<프로젝트 중 특이사항>
# 전문가 평점에서 1점을 받은 자소서(15개) / 5점을 받은 자소서(22개)